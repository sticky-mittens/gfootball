==> Playing in 11_vs_11_stochastic.
==>Level 1
==>OTs in this level are dict_keys(['win_game'])
==>Currently learning win_game
==>using device cuda
==>critic has 2 layers and 3 hidden units.
goal_identified
=== ep: 0, time 26.881362438201904, eps 0.9, right preds for atk and def: 77/164 = 0.4695121951219512, score_diff 0, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 1, time 27.11738657951355, eps 0.8561552526261419, right preds for atk and def: 79/183 = 0.43169398907103823, score_diff 1, tot learning steps 10 (total env steps 3001)
=== ep: 2, time 27.65205955505371, eps 0.8144488388143276, right preds for atk and def: 76/152 = 0.5, score_diff 0, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 3, time 28.285314083099365, eps 0.774776470806127, right preds for atk and def: 55/124 = 0.4435483870967742, score_diff 2, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 4, time 28.10028648376465, eps 0.7370389470171057, right preds for atk and def: 81/171 = 0.47368421052631576, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 5, time 28.43640971183777, eps 0.701141903981193, right preds for atk and def: 88/198 = 0.4444444444444444, score_diff 1, tot learning steps 10 (total env steps 3001)
=== ep: 6, time 29.00673198699951, eps 0.6669955803928644, right preds for atk and def: 67/158 = 0.4240506329113924, score_diff 0, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 7, time 30.157585859298706, eps 0.6345145926571234, right preds for atk and def: 88/179 = 0.49162011173184356, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 8, time 33.273621559143066, eps 0.6036177213860398, right preds for atk and def: 62/150 = 0.41333333333333333, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 9, time 30.457250833511353, eps 0.5742277083079742, right preds for atk and def: 67/147 = 0.4557823129251701, score_diff 2, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 10, time 30.8934268951416, eps 0.5462710630816575, right preds for atk and def: 73/173 = 0.42196531791907516, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 11, time 31.13712239265442, eps 0.5196778795320575, right preds for atk and def: 87/216 = 0.4027777777777778, score_diff 3, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 12, time 31.920447826385498, eps 0.49438166084852986, right preds for atk and def: 105/261 = 0.40229885057471265, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 13, time 34.59510540962219, eps 0.47031915330815344, right preds for atk and def: 88/228 = 0.38596491228070173, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
goal_identified
=== ep: 14, time 37.595032691955566, eps 0.4474301881084772, right preds for atk and def: 76/197 = 0.38578680203045684, score_diff 3, tot learning steps 10 (total env steps 3001)
goal_identified
goal_identified
=== ep: 15, time 39.19928574562073, eps 0.42565753091417224, right preds for atk and def: 76/238 = 0.31932773109243695, score_diff 2, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 16, time 38.09430813789368, eps 0.4049467387413822, right preds for atk and def: 85/228 = 0.37280701754385964, score_diff -1, tot learning steps 10 (total env steps 3001)
=== ep: 17, time 35.596978187561035, eps 0.3852460238219053, right preds for atk and def: 78/196 = 0.3979591836734694, score_diff -1, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 18, time 35.30132055282593, eps 0.3665061241067986, right preds for atk and def: 81/105 = 0.7714285714285715, score_diff 1, tot learning steps 10 (total env steps 3001)
goal_identified
=== ep: 19, time 36.58500838279724, eps 0.3486801800855966, right preds for atk and def: 86/97 = 0.8865979381443299, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 15
goal_identified
goal_identified
=== ep: 20, time 40.76161742210388, eps 0.3317236176131267, right preds for atk and def: 89/106 = 0.839622641509434, score_diff 2, tot learning steps 10 (total env steps 3001)
/home/ksridhar/GRF/scripts/policies.py:457: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
== current size of memory is eps 21 > 20 and we are deleting ep 16
goal_identified
goal_identified
=== ep: 21, time 41.06845474243164, eps 0.31559403645092865, right preds for atk and def: 100/123 = 0.8130081300813008, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 14
=== ep: 22, time 35.484214782714844, eps 0.3002511042445735, right preds for atk and def: 64/77 = 0.8311688311688312, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 13
=== ep: 23, time 33.377543210983276, eps 0.2856564556717689, right preds for atk and def: 83/98 = 0.8469387755102041, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 17
goal_identified
=== ep: 24, time 37.106937885284424, eps 0.27177359650906974, right preds for atk and def: 110/126 = 0.873015873015873, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 12
=== ep: 25, time 38.581098794937134, eps 0.2585678123773109, right preds for atk and def: 75/90 = 0.8333333333333334, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 11
goal_identified
=== ep: 26, time 32.56378650665283, eps 0.24600608193757734, right preds for atk and def: 100/114 = 0.8771929824561403, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 8
goal_identified
=== ep: 27, time 32.30766487121582, eps 0.23405699432065646, right preds for atk and def: 97/105 = 0.9238095238095239, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 10
=== ep: 28, time 35.87770342826843, eps 0.22269067058350425, right preds for atk and def: 66/74 = 0.8918918918918919, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 6
=== ep: 29, time 36.95293402671814, eps 0.2118786889963241, right preds for atk and def: 87/100 = 0.87, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 1
=== ep: 30, time 36.26662516593933, eps 0.2015940139734384, right preds for atk and def: 101/114 = 0.8859649122807017, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 3
goal_identified
goal_identified
=== ep: 31, time 32.307921171188354, eps 0.191810928470242, right preds for atk and def: 92/101 = 0.9108910891089109, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 5
goal_identified
goal_identified
=== ep: 32, time 35.37977337837219, eps 0.1825049696771952, right preds for atk and def: 84/101 = 0.8316831683168316, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 9
=== ep: 33, time 35.9366409778595, eps 0.17365286785005798, right preds for atk and def: 73/93 = 0.7849462365591398, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 0
=== ep: 34, time 30.605754613876343, eps 0.16523248812340846, right preds for atk and def: 78/88 = 0.8863636363636364, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 4
goal_identified
=== ep: 35, time 34.501463413238525, eps 0.15722277516195018, right preds for atk and def: 95/106 = 0.8962264150943396, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 7
=== ep: 36, time 30.30941390991211, eps 0.1496037005112063, right preds for atk and def: 107/112 = 0.9553571428571429, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 2
goal_identified
goal_identified
=== ep: 37, time 34.45506048202515, eps 0.14235621251595124, right preds for atk and def: 101/106 = 0.9528301886792453, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 18
goal_identified
goal_identified
=== ep: 38, time 38.55266761779785, eps 0.13546218868114893, right preds for atk and def: 84/87 = 0.9655172413793104, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 33
goal_identified
=== ep: 39, time 30.863033294677734, eps 0.1289043903562757, right preds for atk and def: 70/78 = 0.8974358974358975, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 21
goal_identified
goal_identified
=== ep: 40, time 34.84305000305176, eps 0.12266641962971482, right preds for atk and def: 60/61 = 0.9836065573770492, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 22
goal_identified
=== ep: 41, time 30.801880359649658, eps 0.116732678325436, right preds for atk and def: 86/92 = 0.9347826086956522, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 32
=== ep: 42, time 36.94385862350464, eps 0.11108832899943073, right preds for atk and def: 71/73 = 0.9726027397260274, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 25
=== ep: 43, time 34.88291692733765, eps 0.10571925783837377, right preds for atk and def: 86/91 = 0.945054945054945, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 20
goal_identified
goal_identified
=== ep: 44, time 31.158400058746338, eps 0.10061203936773815, right preds for atk and def: 82/91 = 0.9010989010989011, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 23
=== ep: 45, time 33.491549253463745, eps 0.09575390288111604, right preds for atk and def: 71/74 = 0.9594594594594594, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 29
goal_identified
=== ep: 46, time 33.61211180686951, eps 0.09113270050680057, right preds for atk and def: 100/105 = 0.9523809523809523, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 24
=== ep: 47, time 34.12637901306152, eps 0.08673687683177911, right preds for atk and def: 92/95 = 0.968421052631579, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 26
goal_identified
=== ep: 48, time 33.093913555145264, eps 0.08255544000718185, right preds for atk and def: 80/85 = 0.9411764705882353, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 30
goal_identified
=== ep: 49, time 30.64064311981201, eps 0.07857793426293408, right preds for atk and def: 71/72 = 0.9861111111111112, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 34
goal_identified
goal_identified
=== ep: 50, time 33.68944001197815, eps 0.07479441376288502, right preds for atk and def: 80/87 = 0.9195402298850575, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 19
goal_identified
goal_identified
goal_identified
=== ep: 51, time 33.27778458595276, eps 0.0711954177350367, right preds for atk and def: 97/101 = 0.9603960396039604, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 28
=== ep: 52, time 37.48990273475647, eps 0.06777194681468615, right preds for atk and def: 106/111 = 0.954954954954955, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 35
=== ep: 53, time 30.966916799545288, eps 0.06451544054132621, right preds for atk and def: 68/69 = 0.9855072463768116, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 39
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 54, time 29.54364538192749, eps 0.06141775595303503, right preds for atk and def: 80/82 = 0.975609756097561, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 44
goal_identified
=== ep: 55, time 37.01541256904602, eps 0.05847114722483011, right preds for atk and def: 104/106 = 0.9811320754716981, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 31
=== ep: 56, time 29.569095611572266, eps 0.05566824630007096, right preds for atk and def: 85/90 = 0.9444444444444444, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 50
goal_identified
=== ep: 57, time 33.22572326660156, eps 0.05300204446647978, right preds for atk and def: 91/92 = 0.9891304347826086, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 27
=== ep: 58, time 30.1174955368042, eps 0.050465874830710106, right preds for atk and def: 88/92 = 0.9565217391304348, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 41
goal_identified
goal_identified
=== ep: 59, time 33.934478521347046, eps 0.04805339564764071, right preds for atk and def: 105/109 = 0.963302752293578, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 48
goal_identified
goal_identified
=== ep: 60, time 30.258527040481567, eps 0.045758574462709686, right preds for atk and def: 97/97 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 56
=== ep: 61, time 37.025432109832764, eps 0.043575673027635695, right preds for atk and def: 110/112 = 0.9821428571428571, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 43
goal_identified
goal_identified
=== ep: 62, time 38.65258479118347, eps 0.04149923295180846, right preds for atk and def: 100/100 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 46
goal_identified
=== ep: 63, time 31.765933990478516, eps 0.03952406205346913, right preds for atk and def: 107/108 = 0.9907407407407407, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 37
goal_identified
goal_identified
=== ep: 64, time 34.7203631401062, eps 0.03764522137655123, right preds for atk and def: 91/94 = 0.9680851063829787, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 52
=== ep: 65, time 31.146273374557495, eps 0.03585801284071809, right preds for atk and def: 80/81 = 0.9876543209876543, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 36
=== ep: 66, time 33.68085980415344, eps 0.034157967493714775, right preds for atk and def: 76/79 = 0.9620253164556962, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 58
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 67, time 30.635244607925415, eps 0.03254083433665968, right preds for atk and def: 71/74 = 0.9594594594594594, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 45
=== ep: 68, time 34.040188789367676, eps 0.031002569694333147, right preds for atk and def: 116/118 = 0.9830508474576272, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 67
=== ep: 69, time 30.34847116470337, eps 0.02953932710388308, right preds for atk and def: 91/91 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 51
=== ep: 70, time 33.56786775588989, eps 0.028147447696664333, right preds for atk and def: 98/102 = 0.9607843137254902, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 70
goal_identified
goal_identified
goal_identified
=== ep: 71, time 37.1036319732666, eps 0.026823451049161253, right preds for atk and def: 79/79 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 66
=== ep: 72, time 40.842830657958984, eps 0.025564026480116013, right preds for atk and def: 88/90 = 0.9777777777777777, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 59
goal_identified
=== ep: 73, time 29.95007872581482, eps 0.02436602477210106, right preds for atk and def: 87/87 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 38
goal_identified
goal_identified
=== ep: 74, time 33.28192710876465, eps 0.02322645029683511, right preds for atk and def: 106/106 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 64
=== ep: 75, time 30.253960132598877, eps 0.02214245352455219, right preds for atk and def: 73/74 = 0.9864864864864865, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 47
goal_identified
=== ep: 76, time 31.758381605148315, eps 0.02111132389869288, right preds for atk and def: 85/87 = 0.9770114942528736, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 42
=== ep: 77, time 31.855320692062378, eps 0.020130483058101077, right preds for atk and def: 89/89 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 54
goal_identified
=== ep: 78, time 32.26886057853699, eps 0.019197478389778148, right preds for atk and def: 84/86 = 0.9767441860465116, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 78
goal_identified
goal_identified
=== ep: 79, time 31.505746603012085, eps 0.018309976896072843, right preds for atk and def: 76/79 = 0.9620253164556962, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 79
=== ep: 80, time 30.967782497406006, eps 0.017465759360972027, right preds for atk and def: 91/93 = 0.978494623655914, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 76
=== ep: 81, time 37.510396242141724, eps 0.01666271480090467, right preds for atk and def: 64/65 = 0.9846153846153847, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 72
goal_identified
goal_identified
=== ep: 82, time 39.343714475631714, eps 0.015898835186183367, right preds for atk and def: 86/86 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 80
=== ep: 83, time 30.07209038734436, eps 0.015172210419884185, right preds for atk and def: 80/81 = 0.9876543209876543, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 55
goal_identified
=== ep: 84, time 31.47102952003479, eps 0.014481023561609456, right preds for atk and def: 65/65 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 61
goal_identified
goal_identified
=== ep: 85, time 29.652970552444458, eps 0.01382354628419033, right preds for atk and def: 69/69 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 68
goal_identified
goal_identified
=== ep: 86, time 31.967379331588745, eps 0.013198134551968641, right preds for atk and def: 85/85 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 40
goal_identified
=== ep: 87, time 29.539567470550537, eps 0.012603224509851407, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 81
=== ep: 88, time 32.01959776878357, eps 0.012037328572858524, right preds for atk and def: 97/98 = 0.9897959183673469, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 53
goal_identified
=== ep: 89, time 29.770837783813477, eps 0.011499031706385502, right preds for atk and def: 97/97 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 49
goal_identified
=== ep: 90, time 31.66309404373169, eps 0.010986987887879832, right preds for atk and def: 63/65 = 0.9692307692307692, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 90
=== ep: 91, time 32.43676996231079, eps 0.010499916741083536, right preds for atk and def: 103/103 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 75
=== ep: 92, time 35.093868017196655, eps 0.010036600334425595, right preds for atk and def: 79/79 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 65
goal_identified
goal_identified
=== ep: 93, time 32.49723958969116, eps 0.00959588013555861, right preds for atk and def: 101/101 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 83
goal_identified
=== ep: 94, time 32.21930146217346, eps 0.009176654114424539, right preds for atk and def: 86/87 = 0.9885057471264368, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 94
goal_identified
goal_identified
=== ep: 95, time 29.703205585479736, eps 0.00877787398760545, right preds for atk and def: 79/79 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 57
=== ep: 96, time 32.35813570022583, eps 0.008398542597069007, right preds for atk and def: 86/87 = 0.9885057471264368, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 96
goal_identified
=== ep: 97, time 29.977497100830078, eps 0.008037711416753971, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 88
=== ep: 98, time 32.47304129600525, eps 0.00769447818076098, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 63
goal_identified
=== ep: 99, time 32.05767869949341, eps 0.007367984627217855, right preds for atk and def: 77/78 = 0.9871794871794872, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 99
=== ep: 100, time 36.00359582901001, eps 0.007057414352177835, right preds for atk and def: 91/92 = 0.9891304347826086, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 100
goal_identified
goal_identified
goal_identified
=== ep: 101, time 32.3696813583374, eps 0.006761990768184489, right preds for atk and def: 91/92 = 0.9891304347826086, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 101
goal_identified
goal_identified
=== ep: 102, time 29.67038607597351, eps 0.006480975162398559, right preds for atk and def: 75/75 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 60
goal_identified
=== ep: 103, time 36.54573154449463, eps 0.006213664849431085, right preds for atk and def: 94/94 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 62
goal_identified
goal_identified
goal_identified
=== ep: 104, time 33.234501361846924, eps 0.005959391414263934, right preds for atk and def: 70/70 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 69
goal_identified
=== ep: 105, time 32.4275107383728, eps 0.005717519040864065, right preds for atk and def: 101/101 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 71
goal_identified
goal_identified
=== ep: 106, time 32.29609394073486, eps 0.005487442922312285, right preds for atk and def: 115/115 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 73
goal_identified
goal_identified
=== ep: 107, time 30.743232488632202, eps 0.005268587748470919, right preds for atk and def: 89/89 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 74
goal_identified
goal_identified
=== ep: 108, time 32.396440744400024, eps 0.005060406267408787, right preds for atk and def: 101/101 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 77
goal_identified
goal_identified
goal_identified
=== ep: 109, time 29.550321102142334, eps 0.004862377916986354, right preds for atk and def: 71/71 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 82
goal_identified
=== ep: 110, time 37.08768892288208, eps 0.004674007523179196, right preds for atk and def: 80/80 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 84
goal_identified
goal_identified
goal_identified
=== ep: 111, time 30.24374485015869, eps 0.004494824061885041, right preds for atk and def: 101/103 = 0.9805825242718447, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 111
goal_identified
=== ep: 112, time 32.43977117538452, eps 0.0043243794811181555, right preds for atk and def: 97/97 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 85
goal_identified
goal_identified
goal_identified
=== ep: 113, time 31.313822269439697, eps 0.0041622475806460035, right preds for atk and def: 93/93 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 86
=== ep: 114, time 36.310075759887695, eps 0.0040080229462666735, right preds for atk and def: 108/108 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 87
goal_identified
goal_identified
=== ep: 115, time 32.672338008880615, eps 0.0038613199360621906, right preds for atk and def: 95/95 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 89
goal_identified
=== ep: 116, time 30.18788242340088, eps 0.003721771716092858, right preds for atk and def: 95/96 = 0.9895833333333334, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 116
goal_identified
=== ep: 117, time 32.56619381904602, eps 0.0035890293431213305, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 91
goal_identified
=== ep: 118, time 29.954366207122803, eps 0.0034627608920727634, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 92
goal_identified
=== ep: 119, time 35.44844365119934, eps 0.00334265062604924, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 93
goal_identified
=== ep: 120, time 30.564688205718994, eps 0.0032283982068230565, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 95
=== ep: 121, time 32.25824522972107, eps 0.0031197179438347193, right preds for atk and def: 74/74 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 97
goal_identified
goal_identified
=== ep: 122, time 30.38011384010315, eps 0.0030163380798177374, right preds for atk and def: 125/125 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 98
goal_identified
=== ep: 123, time 32.283392906188965, eps 0.0029180001112638996, right preds for atk and def: 65/65 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 102
=== ep: 124, time 36.24632811546326, eps 0.002824458142029865, right preds for atk and def: 80/80 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 103
goal_identified
=== ep: 125, time 38.15760946273804, eps 0.0027354782684687108, right preds for atk and def: 64/64 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 104
goal_identified
=== ep: 126, time 32.54471182823181, eps 0.0026508379945489875, right preds for atk and def: 87/87 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 105
goal_identified
=== ep: 127, time 30.27992582321167, eps 0.0025703256754987464, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 106
=== ep: 128, time 32.58659076690674, eps 0.0024937399885833667, right preds for atk and def: 103/103 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 107
goal_identified
goal_identified
=== ep: 129, time 32.490495443344116, eps 0.0024208894296938593, right preds for atk and def: 69/69 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 108
goal_identified
goal_identified
=== ep: 130, time 31.728065252304077, eps 0.0023515918344868374, right preds for atk and def: 91/91 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 109
goal_identified
goal_identified
goal_identified
=== ep: 131, time 29.84009838104248, eps 0.002285673922878779, right preds for atk and def: 83/83 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 110
goal_identified
=== ep: 132, time 32.217145681381226, eps 0.0022229708657555565, right preds for atk and def: 112/112 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 112
goal_identified
goal_identified
goal_identified
=== ep: 133, time 29.929604530334473, eps 0.0021633258728137976, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 113
goal_identified
goal_identified
=== ep: 134, time 32.2166166305542, eps 0.0021065898005034594, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 114
goal_identified
goal_identified
goal_identified
=== ep: 135, time 35.7563693523407, eps 0.002052620779091266, right preds for atk and def: 97/97 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 115
goal_identified
=== ep: 136, time 32.551125049591064, eps 0.0020012838579124784, right preds for atk and def: 80/80 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 117
goal_identified
goal_identified
=== ep: 137, time 32.26913785934448, eps 0.0019524506679239415, right preds for atk and def: 113/113 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 118
goal_identified
=== ep: 138, time 30.4207124710083, eps 0.001905999100714611, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 119
goal_identified
=== ep: 139, time 36.46850061416626, eps 0.001861813003170924, right preds for atk and def: 104/104 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 120
goal_identified
=== ep: 140, time 32.82961368560791, eps 0.0018197818870335101, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 121
=== ep: 141, time 30.34331488609314, eps 0.0017798006526189953, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 122
goal_identified
goal_identified
=== ep: 142, time 32.44851875305176, eps 0.0017417693260160481, right preds for atk and def: 95/95 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 123
goal_identified
=== ep: 143, time 30.047499656677246, eps 0.0017055928090985275, right preds for atk and def: 69/69 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 124
goal_identified
goal_identified
=== ep: 144, time 32.029619455337524, eps 0.0016711806417306348, right preds for atk and def: 81/81 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 125
goal_identified
goal_identified
=== ep: 145, time 34.11424422264099, eps 0.0016384467755694515, right preds for atk and def: 68/68 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 126
=== ep: 146, time 31.093351364135742, eps 0.0016073093588992661, right preds for atk and def: 65/65 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 127
goal_identified
goal_identified
=== ep: 147, time 31.157325983047485, eps 0.0015776905319596466, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 128
goal_identified
goal_identified
goal_identified
=== ep: 148, time 32.07157921791077, eps 0.0015495162322554856, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 129
goal_identified
goal_identified
=== ep: 149, time 30.920686721801758, eps 0.0015227160093621863, right preds for atk and def: 61/61 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 130
=== ep: 150, time 31.402941942214966, eps 0.0014972228487629025, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 131
=== ep: 151, time 31.98335027694702, eps 0.0014729730042773413, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 132
goal_identified
=== ep: 152, time 29.78096055984497, eps 0.001449905838663109, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 133
=== ep: 153, time 32.142242193222046, eps 0.00142796367199102, right preds for atk and def: 79/79 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 134
goal_identified
goal_identified
=== ep: 154, time 32.60452699661255, eps 0.0014070916374152305, right preds for atk and def: 97/97 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 135
goal_identified
=== ep: 155, time 32.191805601119995, eps 0.001387237543977543, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 136
goal_identified
=== ep: 156, time 36.438759326934814, eps 0.0013683517461028282, right preds for atk and def: 92/92 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 137
goal_identified
goal_identified
=== ep: 157, time 36.6517333984375, eps 0.0013503870194592265, right preds for atk and def: 77/77 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 138
goal_identified
goal_identified
=== ep: 158, time 31.761790990829468, eps 0.0013332984428727204, right preds for atk and def: 61/61 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 139
goal_identified
goal_identified
=== ep: 159, time 35.54329442977905, eps 0.001317043286000802, right preds for atk and def: 69/69 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 140
goal_identified
goal_identified
=== ep: 160, time 30.568880081176758, eps 0.0013015809024843582, right preds for atk and def: 92/92 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 141
=== ep: 161, time 32.03987693786621, eps 0.0012868726283106018, right preds for atk and def: 81/81 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 142
=== ep: 162, time 30.92317247390747, eps 0.0012728816851329014, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 143
goal_identified
=== ep: 163, time 29.04551863670349, eps 0.0012595730883057546, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 144
goal_identified
goal_identified
goal_identified
=== ep: 164, time 31.310094356536865, eps 0.001246913559404956, right preds for atk and def: 91/91 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 145
=== ep: 165, time 31.20300793647766, eps 0.0012348714430141991, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 146
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 166, time 28.577226877212524, eps 0.0012234166275700486, right preds for atk and def: 93/93 = 1.0, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 147
goal_identified
goal_identified
=== ep: 167, time 33.872703552246094, eps 0.001212520470067348, right preds for atk and def: 107/107 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 148
=== ep: 168, time 34.8465301990509, eps 0.0012021557244367845, right preds for atk and def: 87/87 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 149
goal_identified
goal_identified
=== ep: 169, time 34.62373161315918, eps 0.0011922964734155277, right preds for atk and def: 83/83 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 150
goal_identified
=== ep: 170, time 31.404581785202026, eps 0.001182918063740569, right preds for atk and def: 113/114 = 0.9912280701754386, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 170
goal_identified
goal_identified
=== ep: 171, time 31.960920572280884, eps 0.0011739970445027263, right preds for atk and def: 101/101 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 151
goal_identified
=== ep: 172, time 29.162710666656494, eps 0.0011655111085071537, right preds for atk and def: 88/88 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 152
goal_identified
=== ep: 173, time 31.298582077026367, eps 0.001157439036493735, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 153
goal_identified
=== ep: 174, time 31.379315614700317, eps 0.0011497606440778825, right preds for atk and def: 100/100 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 154
=== ep: 175, time 37.012085914611816, eps 0.0011424567312790603, right preds for atk and def: 41/41 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 155
goal_identified
=== ep: 176, time 31.009419441223145, eps 0.0011355090345108335, right preds for atk and def: 94/94 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 156
goal_identified
=== ep: 177, time 31.852558374404907, eps 0.0011289001809123877, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 157
goal_identified
goal_identified
goal_identified
=== ep: 178, time 31.498822689056396, eps 0.0011226136449073282, right preds for atk and def: 74/74 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 158
goal_identified
=== ep: 179, time 38.70256757736206, eps 0.001116633706881133, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 159
goal_identified
goal_identified
=== ep: 180, time 31.648154973983765, eps 0.001110945413873925, right preds for atk and def: 101/101 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 160
=== ep: 181, time 28.734715223312378, eps 0.001105534542190287, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 161
goal_identified
=== ep: 182, time 32.13273286819458, eps 0.0011003875618326132, right preds for atk and def: 87/87 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 162
goal_identified
=== ep: 183, time 32.66324234008789, eps 0.0010954916026690664, right preds for atk and def: 105/105 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 163
goal_identified
goal_identified
=== ep: 184, time 29.87477970123291, eps 0.001090834422251547, right preds for atk and def: 98/98 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 164
=== ep: 185, time 33.089481592178345, eps 0.0010864043752031938, right preds for atk and def: 92/92 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 165
goal_identified
goal_identified
goal_identified
=== ep: 186, time 34.418389081954956, eps 0.0010821903840988777, right preds for atk and def: 130/130 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 166
goal_identified
=== ep: 187, time 29.92351222038269, eps 0.0010781819117658682, right preds for atk and def: 63/63 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 167
=== ep: 188, time 35.226560831069946, eps 0.0010743689349354123, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 168
goal_identified
goal_identified
=== ep: 189, time 38.999526500701904, eps 0.0010707419191793434, right preds for atk and def: 92/92 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 169
goal_identified
=== ep: 190, time 39.01336312294006, eps 0.0010672917950690429, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 171
goal_identified
=== ep: 191, time 29.610494136810303, eps 0.0010640099354971456, right preds for atk and def: 115/115 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 172
=== ep: 192, time 30.802314281463623, eps 0.0010608881341052777, right preds for atk and def: 72/72 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 173
goal_identified
=== ep: 193, time 31.32662582397461, eps 0.0010579185847638855, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 174
goal_identified
goal_identified
=== ep: 194, time 28.594159603118896, eps 0.0010550938620528466, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 175
goal_identified
=== ep: 195, time 31.199095726013184, eps 0.001052406902694051, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 176
goal_identified
=== ep: 196, time 31.5860595703125, eps 0.001049850987889527, right preds for atk and def: 88/88 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 177
goal_identified
goal_identified
=== ep: 197, time 28.88605046272278, eps 0.0010474197265209469, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 178
=== ep: 198, time 31.213714599609375, eps 0.0010451070391685015, right preds for atk and def: 86/86 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 179
goal_identified
=== ep: 199, time 31.350995302200317, eps 0.001042907142909185, right preds for atk and def: 70/70 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 180
goal_identified
=== ep: 200, time 35.156901597976685, eps 0.001040814536856474, right preds for atk and def: 79/79 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 181
goal_identified
goal_identified
=== ep: 201, time 35.20931911468506, eps 0.0010388239884052469, right preds for atk and def: 92/92 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 182
goal_identified
=== ep: 202, time 31.911268949508667, eps 0.0010369305201475454, right preds for atk and def: 108/108 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 183
=== ep: 203, time 30.736193418502808, eps 0.0010351293974264616, right preds for atk and def: 80/80 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 184
goal_identified
goal_identified
=== ep: 204, time 30.519129753112793, eps 0.00103341611649703, right preds for atk and def: 43/43 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 185
goal_identified
goal_identified
=== ep: 205, time 31.713942289352417, eps 0.0010317863932645186, right preds for atk and def: 92/92 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 186
goal_identified
=== ep: 206, time 31.902472972869873, eps 0.0010302361525719613, right preds for atk and def: 64/64 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 187
=== ep: 207, time 30.583338737487793, eps 0.0010287615180101426, right preds for atk and def: 67/67 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 188
=== ep: 208, time 33.347920656204224, eps 0.001027358802224555, right preds for atk and def: 74/75 = 0.9866666666666667, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 208
goal_identified
=== ep: 209, time 31.83117437362671, eps 0.0010260244976950921, right preds for atk and def: 72/72 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 189
=== ep: 210, time 33.093713998794556, eps 0.0010247552679654227, right preds for atk and def: 70/70 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 190
=== ep: 211, time 36.24399709701538, eps 0.00102354793930011, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 191
=== ep: 212, time 33.85242557525635, eps 0.0010223994927486214, right preds for atk and def: 87/87 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 192
=== ep: 213, time 30.283684730529785, eps 0.001021307056596379, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 193
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 214, time 29.644145488739014, eps 0.0010202678991839778, right preds for atk and def: 103/103 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 194
=== ep: 215, time 29.959876537322998, eps 0.0010192794220766138, right preds for atk and def: 81/82 = 0.9878048780487805, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 215
goal_identified
goal_identified
=== ep: 216, time 30.447396278381348, eps 0.0010183391535666436, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 195
=== ep: 217, time 28.501535177230835, eps 0.0010174447424930286, right preds for atk and def: 106/106 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 196
goal_identified
goal_identified
=== ep: 218, time 31.13429355621338, eps 0.0010165939523622068, right preds for atk and def: 81/81 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 197
=== ep: 219, time 30.998822927474976, eps 0.0010157846557556941, right preds for atk and def: 86/86 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 198
=== ep: 220, time 29.937379598617554, eps 0.001015014829010431, right preds for atk and def: 107/107 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 199
=== ep: 221, time 35.03239893913269, eps 0.0010142825471585687, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 200
=== ep: 222, time 35.482744455337524, eps 0.0010135859791140496, right preds for atk and def: 82/82 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 201
goal_identified
goal_identified
=== ep: 223, time 35.959996938705444, eps 0.0010129233830939361, right preds for atk and def: 91/92 = 0.9891304347826086, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 223
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 224, time 29.404550790786743, eps 0.0010122931022630473, right preds for atk and def: 78/78 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 202
=== ep: 225, time 36.54344463348389, eps 0.001011693560591007, right preds for atk and def: 64/64 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 203
goal_identified
=== ep: 226, time 31.969515800476074, eps 0.0010111232589113477, right preds for atk and def: 92/92 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 204
goal_identified
goal_identified
=== ep: 227, time 28.234832048416138, eps 0.0010105807711728136, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 205
=== ep: 228, time 30.250407695770264, eps 0.0010100647408734893, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 206
=== ep: 229, time 30.51844620704651, eps 0.001009573877668838, right preds for atk and def: 86/87 = 0.9885057471264368, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 229
goal_identified
goal_identified
=== ep: 230, time 28.302037239074707, eps 0.001009106954145169, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 207
=== ep: 231, time 34.43952512741089, eps 0.0010086628027504636, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 209
goal_identified
=== ep: 232, time 30.934324979782104, eps 0.0010082403128748867, right preds for atk and def: 94/94 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 210
goal_identified
=== ep: 233, time 34.148674964904785, eps 0.0010078384280736842, right preds for atk and def: 64/64 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 211
goal_identified
=== ep: 234, time 30.676411628723145, eps 0.001007456143425521, right preds for atk and def: 97/97 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 212
goal_identified
=== ep: 235, time 30.962384939193726, eps 0.001007092503019653, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 213
=== ep: 236, time 37.01319432258606, eps 0.001006746597565654, right preds for atk and def: 61/61 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 214
goal_identified
=== ep: 237, time 28.720744848251343, eps 0.001006417562119715, right preds for atk and def: 80/80 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 216
goal_identified
goal_identified
=== ep: 238, time 30.380329608917236, eps 0.0010061045739218342, right preds for atk and def: 93/93 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 217
goal_identified
=== ep: 239, time 31.092482566833496, eps 0.0010058068503384884, right preds for atk and def: 114/114 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 218
goal_identified
goal_identified
goal_identified
=== ep: 240, time 30.822404861450195, eps 0.001005523646905642, right preds for atk and def: 105/105 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 219
goal_identified
goal_identified
=== ep: 241, time 34.990675926208496, eps 0.001005254255467199, right preds for atk and def: 112/112 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 220
goal_identified
goal_identified
=== ep: 242, time 31.037336587905884, eps 0.0010049980024042435, right preds for atk and def: 108/108 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 221
=== ep: 243, time 30.754315614700317, eps 0.0010047542469506416, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 222
goal_identified
goal_identified
=== ep: 244, time 32.017922163009644, eps 0.0010045223795907931, right preds for atk and def: 115/115 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 224
=== ep: 245, time 34.58270597457886, eps 0.001004301820535524, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 225
goal_identified
goal_identified
goal_identified
=== ep: 246, time 31.808692932128906, eps 0.0010040920182723119, right preds for atk and def: 93/93 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 226
goal_identified
goal_identified
goal_identified
=== ep: 247, time 28.797329664230347, eps 0.0010038924481862177, right preds for atk and def: 73/73 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 227
goal_identified
=== ep: 248, time 31.02199625968933, eps 0.0010037026112480747, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 228
goal_identified
=== ep: 249, time 31.510491371154785, eps 0.0010035220327666559, right preds for atk and def: 93/94 = 0.9893617021276596, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 249
=== ep: 250, time 28.88777446746826, eps 0.0010033502612016988, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 230
goal_identified
=== ep: 251, time 35.41285181045532, eps 0.001003186867034819, right preds for atk and def: 93/93 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 231
=== ep: 252, time 31.392972469329834, eps 0.001003031441695491, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 232
=== ep: 253, time 31.31382727622986, eps 0.0010028835965394094, right preds for atk and def: 75/75 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 233
goal_identified
=== ep: 254, time 28.97601318359375, eps 0.0010027429618766747, right preds for atk and def: 90/90 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 234
goal_identified
=== ep: 255, time 34.24797749519348, eps 0.0010026091860473767, right preds for atk and def: 51/51 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 235
goal_identified
=== ep: 256, time 34.44117474555969, eps 0.0010024819345422614, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 236
goal_identified
goal_identified
=== ep: 257, time 29.287933349609375, eps 0.0010023608891662839, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 237
=== ep: 258, time 31.708691120147705, eps 0.001002245747242954, right preds for atk and def: 99/99 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 238
=== ep: 259, time 31.75912117958069, eps 0.0010021362208574892, right preds for atk and def: 117/117 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 239
goal_identified
goal_identified
goal_identified
=== ep: 260, time 31.460415840148926, eps 0.001002032036136876, right preds for atk and def: 109/109 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 240
goal_identified
goal_identified
=== ep: 261, time 31.345905780792236, eps 0.0010019329325650452, right preds for atk and def: 55/55 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 241
goal_identified
goal_identified
goal_identified
=== ep: 262, time 33.835482358932495, eps 0.0010018386623314465, right preds for atk and def: 119/119 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 242
goal_identified
=== ep: 263, time 31.24520254135132, eps 0.0010017489897113931, right preds for atk and def: 113/113 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 243
=== ep: 264, time 28.39166283607483, eps 0.0010016636904766263, right preds for atk and def: 84/84 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 244
=== ep: 265, time 30.415245532989502, eps 0.0010015825513346283, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 245
goal_identified
=== ep: 266, time 33.20945382118225, eps 0.0010015053693952815, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 246
=== ep: 267, time 34.650598764419556, eps 0.0010014319516635345, right preds for atk and def: 84/84 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 247
goal_identified
goal_identified
=== ep: 268, time 30.77183198928833, eps 0.0010013621145568167, right preds for atk and def: 61/61 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 248
=== ep: 269, time 30.554930686950684, eps 0.0010012956834459848, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 250
goal_identified
goal_identified
=== ep: 270, time 30.989120721817017, eps 0.0010012324922186594, right preds for atk and def: 82/82 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 251
=== ep: 271, time 36.06928515434265, eps 0.001001172382863857, right preds for atk and def: 56/56 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 252
goal_identified
goal_identified
goal_identified
=== ep: 272, time 31.67570924758911, eps 0.0010011152050768812, right preds for atk and def: 115/115 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 253
=== ep: 273, time 30.849875688552856, eps 0.0010010608158834819, right preds for atk and def: 101/101 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 254
=== ep: 274, time 30.95806860923767, eps 0.0010010090792823456, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 255
goal_identified
goal_identified
=== ep: 275, time 28.47791814804077, eps 0.0010009598659050213, right preds for atk and def: 71/71 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 256
goal_identified
=== ep: 276, time 30.612308979034424, eps 0.0010009130526924313, right preds for atk and def: 83/83 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 257
goal_identified
=== ep: 277, time 31.06830668449402, eps 0.0010008685225871602, right preds for atk and def: 68/68 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 258
goal_identified
goal_identified
goal_identified
=== ep: 278, time 32.449897050857544, eps 0.0010008261642407504, right preds for atk and def: 126/126 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 259
goal_identified
=== ep: 279, time 33.985620975494385, eps 0.001000785871735272, right preds for atk and def: 83/83 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 260
goal_identified
=== ep: 280, time 31.27663230895996, eps 0.0010007475443184742, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 261
goal_identified
goal_identified
goal_identified
=== ep: 281, time 34.58986711502075, eps 0.001000711086151851, right preds for atk and def: 86/86 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 262
=== ep: 282, time 28.383760452270508, eps 0.0010006764060709957, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 263
goal_identified
goal_identified
=== ep: 283, time 30.652873277664185, eps 0.001000643417357642, right preds for atk and def: 83/83 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 264
goal_identified
goal_identified
=== ep: 284, time 30.54223370552063, eps 0.0010006120375228235, right preds for atk and def: 88/88 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 265
goal_identified
goal_identified
goal_identified
=== ep: 285, time 29.613311767578125, eps 0.0010005821881006083, right preds for atk and def: 103/103 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 266
=== ep: 286, time 31.12199592590332, eps 0.0010005537944518927, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 267
=== ep: 287, time 31.45841336250305, eps 0.0010005267855777657, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 268
=== ep: 288, time 31.22300100326538, eps 0.0010005010939419733, right preds for atk and def: 87/87 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 269
goal_identified
goal_identified
=== ep: 289, time 31.253453254699707, eps 0.001000476655302044, right preds for atk and def: 77/77 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 270
goal_identified
=== ep: 290, time 35.2262065410614, eps 0.0010004534085486486, right preds for atk and def: 101/101 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 271
=== ep: 291, time 35.80018877983093, eps 0.0010004312955527947, right preds for atk and def: 115/115 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 272
goal_identified
=== ep: 292, time 32.04945683479309, eps 0.0010004102610204745, right preds for atk and def: 96/96 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 273
=== ep: 293, time 28.732857704162598, eps 0.0010003902523544011, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 274
goal_identified
goal_identified
=== ep: 294, time 32.8517119884491, eps 0.0010003712195224871, right preds for atk and def: 103/103 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 275
goal_identified
=== ep: 295, time 33.00155997276306, eps 0.0010003531149327387, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 276
goal_identified
=== ep: 296, time 30.16257357597351, eps 0.0010003358933142518, right preds for atk and def: 99/99 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 277
goal_identified
goal_identified
goal_identified
=== ep: 297, time 33.41019630432129, eps 0.0010003195116040093, right preds for atk and def: 71/71 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 278
goal_identified
=== ep: 298, time 33.397549867630005, eps 0.0010003039288392032, right preds for atk and def: 83/83 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 279
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 299, time 31.267932891845703, eps 0.0010002891060548044, right preds for atk and def: 73/73 = 1.0, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 280
=== ep: 300, time 36.73680257797241, eps 0.0010002750061861312, right preds for atk and def: 113/113 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 281
=== ep: 301, time 39.90848231315613, eps 0.0010002615939761676, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 282
goal_identified
goal_identified
goal_identified
=== ep: 302, time 32.828705072402954, eps 0.001000248835887403, right preds for atk and def: 77/77 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 283
goal_identified
=== ep: 303, time 28.998096704483032, eps 0.0010002367000179694, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 284
goal_identified
=== ep: 304, time 31.977681159973145, eps 0.0010002251560218723, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 285
=== ep: 305, time 32.792715311050415, eps 0.0010002141750331084, right preds for atk and def: 86/86 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 286
goal_identified
goal_identified
=== ep: 306, time 31.98010563850403, eps 0.0010002037295934862, right preds for atk and def: 86/87 = 0.9885057471264368, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 306
=== ep: 307, time 28.648761510849, eps 0.0010001937935839656, right preds for atk and def: 94/94 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 287
goal_identified
goal_identified
=== ep: 308, time 31.921935558319092, eps 0.0010001843421593476, right preds for atk and def: 91/91 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 288
=== ep: 309, time 30.540629863739014, eps 0.0010001753516861473, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 289
goal_identified
=== ep: 310, time 31.13908863067627, eps 0.0010001667996834991, right preds for atk and def: 106/107 = 0.9906542056074766, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 310
goal_identified
=== ep: 311, time 35.64961338043213, eps 0.001000158664766942, right preds for atk and def: 97/97 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 290
=== ep: 312, time 34.7362494468689, eps 0.0010001509265949466, right preds for atk and def: 103/103 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 291
=== ep: 313, time 35.008816719055176, eps 0.001000143565818053, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 292
goal_identified
goal_identified
=== ep: 314, time 31.326889991760254, eps 0.0010001365640304844, right preds for atk and def: 88/88 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 293
goal_identified
=== ep: 315, time 28.577537298202515, eps 0.0010001299037241253, right preds for atk and def: 69/69 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 294
=== ep: 316, time 31.706526517868042, eps 0.0010001235682447402, right preds for atk and def: 123/123 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 295
goal_identified
=== ep: 317, time 31.41182017326355, eps 0.0010001175417503308, right preds for atk and def: 82/82 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 296
goal_identified
=== ep: 318, time 31.06412410736084, eps 0.0010001118091715218, right preds for atk and def: 70/70 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 297
goal_identified
=== ep: 319, time 29.13503646850586, eps 0.0010001063561738807, right preds for atk and def: 129/129 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 298
goal_identified
goal_identified
=== ep: 320, time 31.114441394805908, eps 0.0010001011691220727, right preds for atk and def: 107/107 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 299
goal_identified
=== ep: 321, time 34.397043228149414, eps 0.0010000962350457665, right preds for atk and def: 65/65 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 300
=== ep: 322, time 31.970731496810913, eps 0.0010000915416072012, right preds for atk and def: 104/104 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 301
goal_identified
=== ep: 323, time 30.809430360794067, eps 0.0010000870770703358, right preds for atk and def: 70/70 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 302
goal_identified
=== ep: 324, time 34.55037879943848, eps 0.0010000828302715028, right preds for atk and def: 107/107 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 303
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 325, time 31.143850564956665, eps 0.0010000787905914928, right preds for atk and def: 73/73 = 1.0, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 304
=== ep: 326, time 30.875458002090454, eps 0.0010000749479290019, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 305
goal_identified
=== ep: 327, time 31.190815925598145, eps 0.001000071292675372, right preds for atk and def: 88/88 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 307
goal_identified
goal_identified
=== ep: 328, time 28.355875730514526, eps 0.001000067815690565, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 308
goal_identified
goal_identified
=== ep: 329, time 31.18198275566101, eps 0.0010000645082803084, right preds for atk and def: 69/69 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 309
goal_identified
=== ep: 330, time 31.781365394592285, eps 0.0010000613621743532, right preds for atk and def: 66/66 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 311
goal_identified
=== ep: 331, time 34.9952130317688, eps 0.0010000583695057963, right preds for atk and def: 111/111 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 312
goal_identified
=== ep: 332, time 28.822369813919067, eps 0.0010000555227914069, right preds for atk and def: 91/92 = 0.9891304347826086, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 332
goal_identified
goal_identified
=== ep: 333, time 30.858287811279297, eps 0.0010000528149129166, right preds for atk and def: 82/82 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 313
goal_identified
goal_identified
=== ep: 334, time 31.534821033477783, eps 0.0010000502390992187, right preds for atk and def: 67/67 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 314
goal_identified
=== ep: 335, time 34.876163482666016, eps 0.0010000477889094373, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 315
goal_identified
=== ep: 336, time 31.33855438232422, eps 0.0010000454582168217, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 316
goal_identified
=== ep: 337, time 32.01765775680542, eps 0.001000043241193426, right preds for atk and def: 75/75 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 317
goal_identified
=== ep: 338, time 31.75993299484253, eps 0.0010000411322955373, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 318
=== ep: 339, time 32.170734882354736, eps 0.0010000391262498123, right preds for atk and def: 80/81 = 0.9876543209876543, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 339
goal_identified
=== ep: 340, time 29.953227758407593, eps 0.001000037218040092, right preds for atk and def: 80/80 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 319
goal_identified
goal_identified
=== ep: 341, time 34.63502049446106, eps 0.0010000354028948577, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 320
goal_identified
goal_identified
=== ep: 342, time 32.802220821380615, eps 0.0010000336762753012, right preds for atk and def: 85/85 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 321
goal_identified
=== ep: 343, time 33.27590608596802, eps 0.001000032033863974, right preds for atk and def: 78/78 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 322
goal_identified
=== ep: 344, time 28.843014240264893, eps 0.0010000304715539925, right preds for atk and def: 105/105 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 323
goal_identified
=== ep: 345, time 32.00603127479553, eps 0.001000028985438768, right preds for atk and def: 67/67 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 324
goal_identified
goal_identified
=== ep: 346, time 33.68649435043335, eps 0.001000027571802238, right preds for atk and def: 87/87 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 325
goal_identified
=== ep: 347, time 35.360116958618164, eps 0.0010000262271095755, right preds for atk and def: 97/97 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 326
goal_identified
=== ep: 348, time 32.535208225250244, eps 0.0010000249479983478, right preds for atk and def: 97/97 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 327
goal_identified
goal_identified
goal_identified
=== ep: 349, time 28.437996864318848, eps 0.0010000237312701107, right preds for atk and def: 99/99 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 328
goal_identified
goal_identified
=== ep: 350, time 32.10045003890991, eps 0.00100002257388241, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 329
goal_identified
=== ep: 351, time 33.98081851005554, eps 0.0010000214729411737, right preds for atk and def: 72/72 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 330
goal_identified
=== ep: 352, time 30.902833938598633, eps 0.0010000204256934752, right preds for atk and def: 104/104 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 331
=== ep: 353, time 29.175498008728027, eps 0.0010000194295206493, right preds for atk and def: 99/99 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 333
=== ep: 354, time 32.00558280944824, eps 0.0010000184819317455, right preds for atk and def: 89/89 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 334
=== ep: 355, time 31.534778118133545, eps 0.001000017580557298, right preds for atk and def: 66/66 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 335
=== ep: 356, time 31.59602451324463, eps 0.001000016723143401, right preds for atk and def: 101/102 = 0.9901960784313726, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 356
goal_identified
goal_identified
=== ep: 357, time 28.739105939865112, eps 0.0010000159075460732, right preds for atk and def: 61/61 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 336
goal_identified
goal_identified
=== ep: 358, time 34.58806252479553, eps 0.0010000151317258964, right preds for atk and def: 88/88 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 337
=== ep: 359, time 34.44392728805542, eps 0.0010000143937429161, right preds for atk and def: 63/63 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 338
goal_identified
goal_identified
=== ep: 360, time 34.37788915634155, eps 0.0010000136917517905, right preds for atk and def: 65/65 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 340
goal_identified
=== ep: 361, time 30.267110109329224, eps 0.001000013023997176, right preds for atk and def: 99/99 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 341
goal_identified
goal_identified
=== ep: 362, time 28.63008713722229, eps 0.0010000123888093385, right preds for atk and def: 77/78 = 0.9871794871794872, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 362
goal_identified
goal_identified
=== ep: 363, time 31.04292058944702, eps 0.0010000117845999773, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 342
goal_identified
=== ep: 364, time 31.730649948120117, eps 0.0010000112098582543, right preds for atk and def: 92/92 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 343
goal_identified
goal_identified
=== ep: 365, time 31.058060884475708, eps 0.001000010663147016, right preds for atk and def: 103/103 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 344
=== ep: 366, time 28.33499836921692, eps 0.0010000101430991996, right preds for atk and def: 101/101 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 345
goal_identified
goal_identified
=== ep: 367, time 30.964085578918457, eps 0.0010000096484144142, right preds for atk and def: 101/101 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 346
goal_identified
goal_identified
goal_identified
=== ep: 368, time 31.577250957489014, eps 0.0010000091778556905, right preds for atk and def: 95/95 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 347
goal_identified
goal_identified
=== ep: 369, time 34.531731367111206, eps 0.0010000087302463867, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 348
goal_identified
goal_identified
goal_identified
=== ep: 370, time 31.446972608566284, eps 0.001000008304467246, right preds for atk and def: 79/79 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 349
goal_identified
=== ep: 371, time 37.79113054275513, eps 0.0010000078994535993, right preds for atk and def: 70/70 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 350
goal_identified
=== ep: 372, time 30.275720357894897, eps 0.0010000075141927012, right preds for atk and def: 61/61 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 351
goal_identified
goal_identified
goal_identified
=== ep: 373, time 30.6757493019104, eps 0.0010000071477211988, right preds for atk and def: 59/59 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 352
goal_identified
=== ep: 374, time 28.219613075256348, eps 0.0010000067991227223, right preds for atk and def: 68/68 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 353
goal_identified
goal_identified
=== ep: 375, time 31.255517721176147, eps 0.0010000064675255943, right preds for atk and def: 66/66 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 354
=== ep: 376, time 30.792585611343384, eps 0.001000006152100649, right preds for atk and def: 99/99 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 355
goal_identified
=== ep: 377, time 30.697226762771606, eps 0.0010000058520591598, right preds for atk and def: 72/72 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 357
=== ep: 378, time 28.841432571411133, eps 0.0010000055666508666, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 358
goal_identified
goal_identified
=== ep: 379, time 30.73513960838318, eps 0.0010000052951621003, right preds for atk and def: 75/75 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 359
goal_identified
goal_identified
goal_identified
=== ep: 380, time 30.88864254951477, eps 0.0010000050369139975, right preds for atk and def: 105/105 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 360
goal_identified
goal_identified
=== ep: 381, time 38.63775873184204, eps 0.001000004791260803, right preds for atk and def: 131/131 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 361
goal_identified
goal_identified
goal_identified
=== ep: 382, time 35.395042181015015, eps 0.0010000045575882562, right preds for atk and def: 86/86 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 363
goal_identified
goal_identified
goal_identified
=== ep: 383, time 28.807035446166992, eps 0.001000004335312054, right preds for atk and def: 95/95 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 364
goal_identified
goal_identified
=== ep: 384, time 31.441115856170654, eps 0.0010000041238763903, right preds for atk and def: 98/98 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 365
=== ep: 385, time 31.05550789833069, eps 0.0010000039227525655, right preds for atk and def: 58/58 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 366
goal_identified
=== ep: 386, time 31.864876747131348, eps 0.0010000037314376652, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 367
=== ep: 387, time 29.522732734680176, eps 0.001000003549453303, right preds for atk and def: 84/84 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 368
goal_identified
=== ep: 388, time 33.32954931259155, eps 0.0010000033763444226, right preds for atk and def: 79/79 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 369
goal_identified
=== ep: 389, time 33.38740921020508, eps 0.001000003211678162, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 370
goal_identified
goal_identified
=== ep: 390, time 33.472975969314575, eps 0.0010000030550427698, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 371
=== ep: 391, time 32.65377688407898, eps 0.0010000029060465757, right preds for atk and def: 84/84 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 372
goal_identified
=== ep: 392, time 36.673879861831665, eps 0.0010000027643170119, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 373
goal_identified
goal_identified
=== ep: 393, time 36.114524126052856, eps 0.0010000026294996803, right preds for atk and def: 67/67 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 374
=== ep: 394, time 32.284398794174194, eps 0.0010000025012574677, right preds for atk and def: 71/72 = 0.9861111111111112, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 394
=== ep: 395, time 32.15215754508972, eps 0.0010000023792697014, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 375
goal_identified
=== ep: 396, time 29.118088960647583, eps 0.0010000022632313489, right preds for atk and def: 94/94 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 376
goal_identified
=== ep: 397, time 30.979764223098755, eps 0.0010000021528522535, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 377
=== ep: 398, time 31.24265480041504, eps 0.00100000204785641, right preds for atk and def: 103/103 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 378
=== ep: 399, time 31.460509061813354, eps 0.0010000019479812744, right preds for atk and def: 77/77 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 379
goal_identified
=== ep: 400, time 31.739526748657227, eps 0.0010000018529771066, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 380
goal_identified
goal_identified
=== ep: 401, time 35.92727828025818, eps 0.0010000017626063467, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 381
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 402, time 31.781881093978882, eps 0.0010000016766430208, right preds for atk and def: 98/98 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 382
=== ep: 403, time 35.45618748664856, eps 0.0010000015948721758, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 383
goal_identified
goal_identified
goal_identified
=== ep: 404, time 31.04229760169983, eps 0.001000001517089342, right preds for atk and def: 95/95 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 384
goal_identified
goal_identified
goal_identified
=== ep: 405, time 31.653780221939087, eps 0.0010000014431000217, right preds for atk and def: 77/77 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 385
=== ep: 406, time 32.841031312942505, eps 0.001000001372719203, right preds for atk and def: 101/101 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 386
=== ep: 407, time 33.438241720199585, eps 0.0010000013057708975, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 387
=== ep: 408, time 30.361788034439087, eps 0.0010000012420876994, right preds for atk and def: 97/97 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 388
=== ep: 409, time 32.96438980102539, eps 0.0010000011815103674, right preds for atk and def: 79/79 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 389
goal_identified
=== ep: 410, time 33.71156620979309, eps 0.001000001123887427, right preds for atk and def: 79/79 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 390
goal_identified
goal_identified
=== ep: 411, time 36.75872206687927, eps 0.0010000010690747903, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 391
goal_identified
=== ep: 412, time 30.369313955307007, eps 0.0010000010169353975, right preds for atk and def: 72/72 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 392
goal_identified
=== ep: 413, time 33.5639111995697, eps 0.0010000009673388729, right preds for atk and def: 77/77 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 393
goal_identified
=== ep: 414, time 36.308228492736816, eps 0.0010000009201611994, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 395
goal_identified
=== ep: 415, time 37.01789426803589, eps 0.0010000008752844081, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 396
goal_identified
=== ep: 416, time 30.2894606590271, eps 0.0010000008325962838, right preds for atk and def: 86/86 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 397
goal_identified
=== ep: 417, time 34.62884998321533, eps 0.001000000791990084, right preds for atk and def: 92/92 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 398
goal_identified
=== ep: 418, time 34.67006206512451, eps 0.0010000007533642718, right preds for atk and def: 69/69 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 399
=== ep: 419, time 34.775752544403076, eps 0.0010000007166222626, right preds for atk and def: 104/104 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 400
goal_identified
goal_identified
=== ep: 420, time 34.596941232681274, eps 0.0010000006816721825, right preds for atk and def: 117/117 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 401
=== ep: 421, time 34.519901514053345, eps 0.001000000648426638, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 402
goal_identified
=== ep: 422, time 34.9000198841095, eps 0.0010000006168024976, right preds for atk and def: 82/82 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 403
goal_identified
=== ep: 423, time 31.334593057632446, eps 0.0010000005867206849, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 404
goal_identified
=== ep: 424, time 33.73123288154602, eps 0.0010000005581059794, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 405
goal_identified
goal_identified
goal_identified
=== ep: 425, time 37.148414850234985, eps 0.0010000005308868295, right preds for atk and def: 97/97 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 406
goal_identified
=== ep: 426, time 36.823105335235596, eps 0.0010000005049951733, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 407
goal_identified
goal_identified
=== ep: 427, time 33.79362106323242, eps 0.001000000480366268, right preds for atk and def: 73/73 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 408
=== ep: 428, time 30.687066793441772, eps 0.0010000004569385287, right preds for atk and def: 105/105 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 409
goal_identified
goal_identified
goal_identified
=== ep: 429, time 33.80979824066162, eps 0.0010000004346533736, right preds for atk and def: 61/61 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 410
=== ep: 430, time 35.03060460090637, eps 0.0010000004134550786, right preds for atk and def: 61/61 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 411
goal_identified
goal_identified
=== ep: 431, time 32.75594711303711, eps 0.0010000003932906364, right preds for atk and def: 66/66 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 412
goal_identified
=== ep: 432, time 29.875011682510376, eps 0.0010000003741096257, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 413
=== ep: 433, time 33.46521186828613, eps 0.001000000355864084, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 414
goal_identified
goal_identified
=== ep: 434, time 33.42016673088074, eps 0.0010000003385083878, right preds for atk and def: 96/96 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 415
=== ep: 435, time 35.607420921325684, eps 0.001000000321999139, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 416
goal_identified
goal_identified
goal_identified
=== ep: 436, time 33.712042808532715, eps 0.0010000003062950555, right preds for atk and def: 83/83 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 417
=== ep: 437, time 36.069862842559814, eps 0.0010000002913568694, right preds for atk and def: 87/87 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 418
goal_identified
=== ep: 438, time 33.02452301979065, eps 0.0010000002771472273, right preds for atk and def: 90/90 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 419
goal_identified
=== ep: 439, time 36.16191506385803, eps 0.0010000002636305976, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 420
=== ep: 440, time 30.475050687789917, eps 0.0010000002507731815, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 421
goal_identified
=== ep: 441, time 33.095447063446045, eps 0.0010000002385428292, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 422
=== ep: 442, time 32.960031270980835, eps 0.0010000002269089582, right preds for atk and def: 62/63 = 0.9841269841269841, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 442
goal_identified
=== ep: 443, time 33.320969581604004, eps 0.0010000002158424776, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 423
goal_identified
=== ep: 444, time 29.90589714050293, eps 0.0010000002053157158, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 424
goal_identified
=== ep: 445, time 33.260459184646606, eps 0.0010000001953023503, right preds for atk and def: 90/90 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 425
=== ep: 446, time 34.820722579956055, eps 0.001000000185777342, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 426
=== ep: 447, time 35.891499280929565, eps 0.0010000001767168742, right preds for atk and def: 75/75 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 427
=== ep: 448, time 33.070720911026, eps 0.0010000001680982905, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 428
goal_identified
goal_identified
=== ep: 449, time 35.40365290641785, eps 0.0010000001599000403, right preds for atk and def: 61/61 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 429
goal_identified
goal_identified
=== ep: 450, time 32.60216736793518, eps 0.0010000001521016232, right preds for atk and def: 92/92 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 430
=== ep: 451, time 33.09037804603577, eps 0.0010000001446835395, right preds for atk and def: 97/97 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 431
goal_identified
=== ep: 452, time 32.000755071640015, eps 0.0010000001376272401, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 432
goal_identified
=== ep: 453, time 34.04583382606506, eps 0.0010000001309150804, right preds for atk and def: 115/115 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 433
goal_identified
goal_identified
goal_identified
=== ep: 454, time 33.73200535774231, eps 0.0010000001245302765, right preds for atk and def: 95/95 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 434
goal_identified
=== ep: 455, time 34.47756028175354, eps 0.0010000001184568633, right preds for atk and def: 95/95 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 435
=== ep: 456, time 31.397237539291382, eps 0.0010000001126796538, right preds for atk and def: 105/105 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 436
goal_identified
goal_identified
=== ep: 457, time 37.14178800582886, eps 0.0010000001071842023, right preds for atk and def: 66/66 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 437
goal_identified
=== ep: 458, time 39.02125263214111, eps 0.001000000101956767, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 438
goal_identified
goal_identified
goal_identified
=== ep: 459, time 38.604424238204956, eps 0.001000000096984277, right preds for atk and def: 89/89 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 439
goal_identified
=== ep: 460, time 32.319544553756714, eps 0.001000000092254298, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 440
=== ep: 461, time 35.70602869987488, eps 0.0010000000877550027, right preds for atk and def: 113/113 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 441
=== ep: 462, time 34.26724553108215, eps 0.0010000000834751407, right preds for atk and def: 90/90 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 443
goal_identified
=== ep: 463, time 34.67910432815552, eps 0.00100000007940401, right preds for atk and def: 83/83 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 444
goal_identified
goal_identified
=== ep: 464, time 31.94139051437378, eps 0.0010000000755314307, right preds for atk and def: 89/89 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 445
goal_identified
goal_identified
=== ep: 465, time 34.550174951553345, eps 0.0010000000718477194, right preds for atk and def: 81/81 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 446
=== ep: 466, time 34.302878618240356, eps 0.0010000000683436647, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 447
goal_identified
=== ep: 467, time 34.93320322036743, eps 0.001000000065010505, right preds for atk and def: 78/78 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 448
goal_identified
=== ep: 468, time 38.27292537689209, eps 0.0010000000618399052, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 449
goal_identified
goal_identified
goal_identified
=== ep: 469, time 37.79780578613281, eps 0.0010000000588239375, right preds for atk and def: 117/117 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 450
goal_identified
goal_identified
goal_identified
=== ep: 470, time 37.773200273513794, eps 0.0010000000559550603, right preds for atk and def: 94/94 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 451
goal_identified
=== ep: 471, time 34.5784478187561, eps 0.0010000000532260998, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 452
=== ep: 472, time 32.363884925842285, eps 0.0010000000506302322, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 453
goal_identified
=== ep: 473, time 34.48145031929016, eps 0.0010000000481609666, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 454
goal_identified
goal_identified
goal_identified
=== ep: 474, time 34.52495765686035, eps 0.0010000000458121286, right preds for atk and def: 67/67 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 455
=== ep: 475, time 34.08770275115967, eps 0.0010000000435778447, right preds for atk and def: 105/105 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 456
goal_identified
=== ep: 476, time 31.133097648620605, eps 0.001000000041452528, right preds for atk and def: 80/80 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 457
goal_identified
=== ep: 477, time 34.308406591415405, eps 0.0010000000394308644, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 458
goal_identified
goal_identified
=== ep: 478, time 37.26681089401245, eps 0.0010000000375077985, right preds for atk and def: 94/94 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 459
goal_identified
goal_identified
goal_identified
=== ep: 479, time 37.76986861228943, eps 0.0010000000356785216, right preds for atk and def: 100/100 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 460
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 480, time 35.056214809417725, eps 0.0010000000339384595, right preds for atk and def: 79/79 = 1.0, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 461
=== ep: 481, time 34.628586769104004, eps 0.0010000000322832614, right preds for atk and def: 97/97 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 462
goal_identified
=== ep: 482, time 33.71933460235596, eps 0.0010000000307087882, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 463
goal_identified
goal_identified
goal_identified
=== ep: 483, time 33.82829976081848, eps 0.001000000029211103, right preds for atk and def: 79/79 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 464
=== ep: 484, time 30.849706172943115, eps 0.0010000000277864607, right preds for atk and def: 85/85 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 465
goal_identified
goal_identified
goal_identified
=== ep: 485, time 33.140257120132446, eps 0.0010000000264312988, right preds for atk and def: 61/61 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 466
goal_identified
=== ep: 486, time 33.147979497909546, eps 0.0010000000251422292, right preds for atk and def: 97/97 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 467
=== ep: 487, time 33.33036422729492, eps 0.0010000000239160282, right preds for atk and def: 79/79 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 468
goal_identified
=== ep: 488, time 32.83436059951782, eps 0.00100000002274963, right preds for atk and def: 66/66 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 469
=== ep: 489, time 32.841357946395874, eps 0.0010000000216401172, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 470
goal_identified
goal_identified
goal_identified
=== ep: 490, time 36.105053186416626, eps 0.0010000000205847162, right preds for atk and def: 89/89 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 471
=== ep: 491, time 35.60953330993652, eps 0.0010000000195807877, right preds for atk and def: 88/88 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 472
goal_identified
=== ep: 492, time 33.132747173309326, eps 0.0010000000186258216, right preds for atk and def: 83/84 = 0.9880952380952381, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 492
goal_identified
=== ep: 493, time 30.64883804321289, eps 0.0010000000177174295, right preds for atk and def: 80/80 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 473
goal_identified
goal_identified
=== ep: 494, time 33.21123456954956, eps 0.0010000000168533404, right preds for atk and def: 99/99 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 474
=== ep: 495, time 32.86065149307251, eps 0.0010000000160313932, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 475
goal_identified
goal_identified
goal_identified
=== ep: 496, time 33.26667237281799, eps 0.001000000015249533, right preds for atk and def: 87/87 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 476
goal_identified
=== ep: 497, time 30.024165391921997, eps 0.0010000000145058043, right preds for atk and def: 79/79 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 477
goal_identified
goal_identified
goal_identified
=== ep: 498, time 34.752140522003174, eps 0.001000000013798348, right preds for atk and def: 73/73 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 478
goal_identified
=== ep: 499, time 33.36056327819824, eps 0.0010000000131253947, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 479
goal_identified
goal_identified
=== ep: 500, time 32.985411643981934, eps 0.0010000000124852615, right preds for atk and def: 84/84 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 480
goal_identified
=== ep: 501, time 33.1874566078186, eps 0.0010000000118763482, right preds for atk and def: 100/100 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 481
goal_identified
=== ep: 502, time 34.91027355194092, eps 0.0010000000112971319, right preds for atk and def: 103/103 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 482
goal_identified
=== ep: 503, time 34.405728578567505, eps 0.0010000000107461642, right preds for atk and def: 113/113 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 483
goal_identified
goal_identified
=== ep: 504, time 33.199134349823, eps 0.0010000000102220676, right preds for atk and def: 77/77 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 484
goal_identified
goal_identified
=== ep: 505, time 30.14734411239624, eps 0.0010000000097235315, right preds for atk and def: 105/105 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 485
goal_identified
=== ep: 506, time 33.4574179649353, eps 0.0010000000092493092, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 486
=== ep: 507, time 33.70095372200012, eps 0.0010000000087982152, right preds for atk and def: 94/94 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 487
goal_identified
=== ep: 508, time 36.00752329826355, eps 0.0010000000083691212, right preds for atk and def: 110/110 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 488
goal_identified
=== ep: 509, time 30.66489315032959, eps 0.0010000000079609542, right preds for atk and def: 79/79 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 489
goal_identified
=== ep: 510, time 33.00729012489319, eps 0.001000000007572694, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 490
goal_identified
goal_identified
=== ep: 511, time 33.657609701156616, eps 0.0010000000072033692, right preds for atk and def: 100/100 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 491
goal_identified
=== ep: 512, time 35.366140365600586, eps 0.001000000006852057, right preds for atk and def: 105/105 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 493
goal_identified
=== ep: 513, time 35.3498113155365, eps 0.001000000006517878, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 494
goal_identified
goal_identified
=== ep: 514, time 35.46393084526062, eps 0.0010000000061999974, right preds for atk and def: 74/74 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 495
=== ep: 515, time 30.83503484725952, eps 0.0010000000058976199, right preds for atk and def: 53/53 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 496
goal_identified
=== ep: 516, time 33.89330506324768, eps 0.0010000000056099897, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 497
goal_identified
=== ep: 517, time 31.630959272384644, eps 0.0010000000053363872, right preds for atk and def: 105/105 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 498
goal_identified
goal_identified
=== ep: 518, time 38.37100338935852, eps 0.0010000000050761286, right preds for atk and def: 85/85 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 499
=== ep: 519, time 34.807270765304565, eps 0.001000000004828563, right preds for atk and def: 99/99 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 500
=== ep: 520, time 34.54905962944031, eps 0.001000000004593071, right preds for atk and def: 101/101 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 501
goal_identified
=== ep: 521, time 31.26624298095703, eps 0.0010000000043690644, right preds for atk and def: 77/77 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 502
=== ep: 522, time 34.752228021621704, eps 0.0010000000041559827, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 503
=== ep: 523, time 37.15576720237732, eps 0.0010000000039532928, right preds for atk and def: 73/73 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 504
goal_identified
goal_identified
goal_identified
=== ep: 524, time 38.88505244255066, eps 0.0010000000037604885, right preds for atk and def: 94/94 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 505
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 525, time 37.05511951446533, eps 0.0010000000035770874, right preds for atk and def: 95/95 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 506
=== ep: 526, time 34.57283306121826, eps 0.0010000000034026306, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 507
=== ep: 527, time 38.20355439186096, eps 0.0010000000032366824, right preds for atk and def: 96/96 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 508
=== ep: 528, time 34.31474256515503, eps 0.0010000000030788276, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 509
=== ep: 529, time 34.377986669540405, eps 0.0010000000029286714, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 510
goal_identified
goal_identified
goal_identified
=== ep: 530, time 35.724844455718994, eps 0.0010000000027858384, right preds for atk and def: 133/133 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 511
=== ep: 531, time 34.5408673286438, eps 0.0010000000026499714, right preds for atk and def: 107/107 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 512
goal_identified
=== ep: 532, time 34.19312143325806, eps 0.0010000000025207308, right preds for atk and def: 93/93 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 513
=== ep: 533, time 31.83975648880005, eps 0.0010000000023977934, right preds for atk and def: 101/101 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 514
goal_identified
=== ep: 534, time 36.749042987823486, eps 0.0010000000022808515, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 515
goal_identified
=== ep: 535, time 37.87013864517212, eps 0.0010000000021696133, right preds for atk and def: 87/87 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 516
goal_identified
=== ep: 536, time 36.43314027786255, eps 0.0010000000020637999, right preds for atk and def: 87/87 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 517
goal_identified
=== ep: 537, time 34.773032665252686, eps 0.0010000000019631471, right preds for atk and def: 79/79 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 518
goal_identified
goal_identified
goal_identified
=== ep: 538, time 33.68660306930542, eps 0.0010000000018674034, right preds for atk and def: 89/89 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 519
=== ep: 539, time 33.385342597961426, eps 0.001000000001776329, right preds for atk and def: 67/67 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 520
goal_identified
=== ep: 540, time 33.75216364860535, eps 0.0010000000016896964, right preds for atk and def: 100/100 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 521
goal_identified
=== ep: 541, time 30.825551748275757, eps 0.001000000001607289, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 522
goal_identified
=== ep: 542, time 33.217918395996094, eps 0.0010000000015289005, right preds for atk and def: 106/106 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 523
goal_identified
=== ep: 543, time 33.648945331573486, eps 0.0010000000014543352, right preds for atk and def: 71/71 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 524
goal_identified
=== ep: 544, time 34.13091993331909, eps 0.0010000000013834064, right preds for atk and def: 73/73 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 525
=== ep: 545, time 35.40546274185181, eps 0.001000000001315937, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 526
goal_identified
goal_identified
=== ep: 546, time 38.6187686920166, eps 0.0010000000012517578, right preds for atk and def: 78/78 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 527
goal_identified
=== ep: 547, time 33.35570764541626, eps 0.001000000001190709, right preds for atk and def: 90/90 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 528
goal_identified
=== ep: 548, time 33.62164831161499, eps 0.0010000000011326374, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 529
=== ep: 549, time 34.21584343910217, eps 0.001000000001077398, right preds for atk and def: 81/82 = 0.9878048780487805, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 549
=== ep: 550, time 33.755226135253906, eps 0.0010000000010248527, right preds for atk and def: 82/82 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 530
goal_identified
=== ep: 551, time 33.383172273635864, eps 0.00100000000097487, right preds for atk and def: 92/92 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 531
goal_identified
goal_identified
=== ep: 552, time 34.23519730567932, eps 0.001000000000927325, right preds for atk and def: 109/109 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 532
goal_identified
=== ep: 553, time 33.87411165237427, eps 0.0010000000008820989, right preds for atk and def: 111/111 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 533
=== ep: 554, time 34.592517614364624, eps 0.0010000000008390784, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 534
goal_identified
goal_identified
=== ep: 555, time 37.9734992980957, eps 0.001000000000798156, right preds for atk and def: 115/115 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 535
goal_identified
=== ep: 556, time 41.55008268356323, eps 0.0010000000007592295, right preds for atk and def: 105/105 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 536
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 557, time 37.23172903060913, eps 0.0010000000007222014, right preds for atk and def: 95/95 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 537
=== ep: 558, time 31.157113552093506, eps 0.0010000000006869794, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 538
goal_identified
=== ep: 559, time 34.99450492858887, eps 0.001000000000653475, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 539
goal_identified
goal_identified
=== ep: 560, time 34.46871995925903, eps 0.0010000000006216046, right preds for atk and def: 85/85 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 540
goal_identified
goal_identified
=== ep: 561, time 33.259033203125, eps 0.0010000000005912885, right preds for atk and def: 83/83 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 541
=== ep: 562, time 35.138980865478516, eps 0.0010000000005624511, right preds for atk and def: 86/86 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 542
=== ep: 563, time 34.586256980895996, eps 0.00100000000053502, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 543
goal_identified
=== ep: 564, time 34.426915407180786, eps 0.001000000000508927, right preds for atk and def: 101/101 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 544
goal_identified
goal_identified
=== ep: 565, time 33.09552764892578, eps 0.001000000000484106, right preds for atk and def: 83/83 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 545
goal_identified
goal_identified
=== ep: 566, time 39.44311451911926, eps 0.001000000000460496, right preds for atk and def: 101/102 = 0.9901960784313726, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 566
goal_identified
=== ep: 567, time 37.74007987976074, eps 0.0010000000004380374, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 546
=== ep: 568, time 38.095288038253784, eps 0.001000000000416674, right preds for atk and def: 83/83 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 547
=== ep: 569, time 35.54820156097412, eps 0.0010000000003963527, right preds for atk and def: 85/85 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 548
goal_identified
goal_identified
=== ep: 570, time 32.668530225753784, eps 0.0010000000003770222, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 550
=== ep: 571, time 35.53968358039856, eps 0.0010000000003586346, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 551
goal_identified
goal_identified
=== ep: 572, time 34.861533641815186, eps 0.0010000000003411438, right preds for atk and def: 68/68 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 552
goal_identified
=== ep: 573, time 34.809847593307495, eps 0.001000000000324506, right preds for atk and def: 65/65 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 553
=== ep: 574, time 33.78068423271179, eps 0.0010000000003086798, right preds for atk and def: 89/89 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 554
goal_identified
=== ep: 575, time 36.11065912246704, eps 0.0010000000002936252, right preds for atk and def: 57/57 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 555
goal_identified
goal_identified
goal_identified
=== ep: 576, time 34.66213607788086, eps 0.001000000000279305, right preds for atk and def: 126/126 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 556
=== ep: 577, time 38.324037075042725, eps 0.0010000000002656831, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 557
goal_identified
goal_identified
=== ep: 578, time 34.935622453689575, eps 0.0010000000002527256, right preds for atk and def: 85/85 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 558
=== ep: 579, time 34.161094427108765, eps 0.0010000000002404, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 559
=== ep: 580, time 34.27775478363037, eps 0.0010000000002286756, right preds for atk and def: 99/99 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 560
goal_identified
=== ep: 581, time 34.422616958618164, eps 0.0010000000002175229, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 561
goal_identified
goal_identified
goal_identified
=== ep: 582, time 31.61263394355774, eps 0.0010000000002069142, right preds for atk and def: 107/107 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 562
=== ep: 583, time 34.40645146369934, eps 0.0010000000001968228, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 563
goal_identified
=== ep: 584, time 34.23257756233215, eps 0.0010000000001872237, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 564
goal_identified
goal_identified
=== ep: 585, time 37.94282507896423, eps 0.0010000000001780928, right preds for atk and def: 87/87 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 565
=== ep: 586, time 33.59410643577576, eps 0.001000000000169407, right preds for atk and def: 96/96 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 567
goal_identified
=== ep: 587, time 36.023723125457764, eps 0.001000000000161145, right preds for atk and def: 71/71 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 568
goal_identified
goal_identified
=== ep: 588, time 36.626588106155396, eps 0.0010000000001532858, right preds for atk and def: 107/107 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 569
goal_identified
=== ep: 589, time 36.72921085357666, eps 0.00100000000014581, right preds for atk and def: 108/108 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 570
goal_identified
goal_identified
goal_identified
=== ep: 590, time 34.50054907798767, eps 0.0010000000001386988, right preds for atk and def: 89/89 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 571
=== ep: 591, time 30.82294249534607, eps 0.0010000000001319344, right preds for atk and def: 96/96 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 572
=== ep: 592, time 34.9479763507843, eps 0.0010000000001255, right preds for atk and def: 118/118 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 573
goal_identified
=== ep: 593, time 35.13088321685791, eps 0.0010000000001193791, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 574
goal_identified
=== ep: 594, time 37.93439173698425, eps 0.001000000000113557, right preds for atk and def: 106/106 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 575
goal_identified
goal_identified
=== ep: 595, time 35.50295448303223, eps 0.0010000000001080186, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 576
goal_identified
goal_identified
=== ep: 596, time 34.73876595497131, eps 0.0010000000001027505, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 577
=== ep: 597, time 35.27445721626282, eps 0.0010000000000977393, right preds for atk and def: 75/75 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 578
=== ep: 598, time 38.754454135894775, eps 0.0010000000000929725, right preds for atk and def: 107/107 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 579
=== ep: 599, time 38.910768270492554, eps 0.0010000000000884382, right preds for atk and def: 85/85 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 580
goal_identified
goal_identified
=== ep: 600, time 34.69004726409912, eps 0.001000000000084125, right preds for atk and def: 97/97 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 581
goal_identified
=== ep: 601, time 34.819053649902344, eps 0.0010000000000800222, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 582
=== ep: 602, time 35.13657760620117, eps 0.0010000000000761195, right preds for atk and def: 68/68 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 583
goal_identified
goal_identified
=== ep: 603, time 35.06469464302063, eps 0.0010000000000724072, right preds for atk and def: 78/78 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 584
goal_identified
goal_identified
=== ep: 604, time 33.78616738319397, eps 0.0010000000000688757, right preds for atk and def: 64/64 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 585
goal_identified
=== ep: 605, time 33.908632040023804, eps 0.0010000000000655166, right preds for atk and def: 74/74 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 586
goal_identified
=== ep: 606, time 33.85596013069153, eps 0.0010000000000623215, right preds for atk and def: 78/78 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 587
goal_identified
goal_identified
=== ep: 607, time 31.349504232406616, eps 0.001000000000059282, right preds for atk and def: 97/97 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 588
goal_identified
=== ep: 608, time 35.11674904823303, eps 0.0010000000000563907, right preds for atk and def: 85/85 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 589
=== ep: 609, time 38.66940975189209, eps 0.0010000000000536405, right preds for atk and def: 103/103 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 590
goal_identified
goal_identified
goal_identified
=== ep: 610, time 37.02139377593994, eps 0.0010000000000510245, right preds for atk and def: 109/109 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 591
=== ep: 611, time 34.29954957962036, eps 0.0010000000000485358, right preds for atk and def: 109/109 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 592
=== ep: 612, time 30.563351154327393, eps 0.0010000000000461688, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 593
goal_identified
goal_identified
=== ep: 613, time 36.89493203163147, eps 0.0010000000000439171, right preds for atk and def: 92/92 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 594
goal_identified
=== ep: 614, time 33.972086906433105, eps 0.0010000000000417752, right preds for atk and def: 89/89 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 595
goal_identified
goal_identified
goal_identified
=== ep: 615, time 33.654178619384766, eps 0.0010000000000397378, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 596
goal_identified
=== ep: 616, time 30.712806940078735, eps 0.0010000000000377999, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 597
goal_identified
=== ep: 617, time 33.88392925262451, eps 0.0010000000000359563, right preds for atk and def: 93/93 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 598
=== ep: 618, time 33.933748722076416, eps 0.0010000000000342027, right preds for atk and def: 98/98 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 599
goal_identified
=== ep: 619, time 33.768301248550415, eps 0.0010000000000325345, right preds for atk and def: 94/94 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 600
goal_identified
=== ep: 620, time 35.80570650100708, eps 0.001000000000030948, right preds for atk and def: 87/87 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 601
goal_identified
goal_identified
=== ep: 621, time 36.28421068191528, eps 0.0010000000000294385, right preds for atk and def: 115/115 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 602
goal_identified
goal_identified
=== ep: 622, time 37.44026064872742, eps 0.0010000000000280028, right preds for atk and def: 112/112 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 603
goal_identified
goal_identified
goal_identified
=== ep: 623, time 34.332698822021484, eps 0.0010000000000266371, right preds for atk and def: 88/88 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 604
=== ep: 624, time 34.25933384895325, eps 0.001000000000025338, right preds for atk and def: 112/112 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 605
=== ep: 625, time 31.310357332229614, eps 0.0010000000000241023, right preds for atk and def: 87/87 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 606
goal_identified
=== ep: 626, time 34.037625789642334, eps 0.0010000000000229268, right preds for atk and def: 83/83 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 607
=== ep: 627, time 34.291332721710205, eps 0.0010000000000218085, right preds for atk and def: 92/92 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 608
goal_identified
goal_identified
goal_identified
=== ep: 628, time 34.136340618133545, eps 0.001000000000020745, right preds for atk and def: 93/94 = 0.9893617021276596, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 628
goal_identified
goal_identified
=== ep: 629, time 30.768901824951172, eps 0.0010000000000197332, right preds for atk and def: 69/69 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 609
goal_identified
=== ep: 630, time 34.46483778953552, eps 0.0010000000000187708, right preds for atk and def: 106/106 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 610
=== ep: 631, time 35.713844776153564, eps 0.0010000000000178553, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 611
goal_identified
goal_identified
goal_identified
=== ep: 632, time 40.5467472076416, eps 0.0010000000000169845, right preds for atk and def: 79/79 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 612
goal_identified
goal_identified
=== ep: 633, time 34.11904168128967, eps 0.0010000000000161562, right preds for atk and def: 97/97 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 613
=== ep: 634, time 31.03693652153015, eps 0.0010000000000153684, right preds for atk and def: 106/106 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 614
goal_identified
=== ep: 635, time 33.789944887161255, eps 0.0010000000000146188, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 615
=== ep: 636, time 33.921175718307495, eps 0.0010000000000139058, right preds for atk and def: 84/84 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 616
=== ep: 637, time 34.3129677772522, eps 0.0010000000000132275, right preds for atk and def: 83/84 = 0.9880952380952381, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 637
goal_identified
=== ep: 638, time 31.602481365203857, eps 0.0010000000000125824, right preds for atk and def: 113/113 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 617
goal_identified
=== ep: 639, time 34.36264777183533, eps 0.0010000000000119687, right preds for atk and def: 79/80 = 0.9875, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 639
goal_identified
=== ep: 640, time 34.19843673706055, eps 0.001000000000011385, right preds for atk and def: 70/70 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 618
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 641, time 38.236061096191406, eps 0.00100000000001083, right preds for atk and def: 98/98 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 619
goal_identified
=== ep: 642, time 34.997594356536865, eps 0.0010000000000103017, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 620
=== ep: 643, time 38.35254526138306, eps 0.0010000000000097993, right preds for atk and def: 74/74 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 621
=== ep: 644, time 36.00945210456848, eps 0.0010000000000093213, right preds for atk and def: 110/110 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 622
=== ep: 645, time 35.52308797836304, eps 0.0010000000000088666, right preds for atk and def: 111/111 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 623
goal_identified
=== ep: 646, time 31.63215470314026, eps 0.0010000000000084342, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 624
=== ep: 647, time 34.76352620124817, eps 0.001000000000008023, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 625
goal_identified
=== ep: 648, time 34.49276041984558, eps 0.0010000000000076317, right preds for atk and def: 88/88 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 626
=== ep: 649, time 34.32460927963257, eps 0.0010000000000072594, right preds for atk and def: 83/83 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 627
goal_identified
goal_identified
=== ep: 650, time 33.04173517227173, eps 0.0010000000000069055, right preds for atk and def: 98/98 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 629
=== ep: 651, time 33.62331032752991, eps 0.0010000000000065686, right preds for atk and def: 67/67 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 630
=== ep: 652, time 34.499879598617554, eps 0.0010000000000062483, right preds for atk and def: 99/99 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 631
goal_identified
=== ep: 653, time 35.43986773490906, eps 0.0010000000000059436, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 632
=== ep: 654, time 36.790390968322754, eps 0.0010000000000056537, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 633
goal_identified
goal_identified
=== ep: 655, time 31.747329711914062, eps 0.0010000000000053779, right preds for atk and def: 106/106 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 634
goal_identified
=== ep: 656, time 33.89626908302307, eps 0.0010000000000051157, right preds for atk and def: 109/110 = 0.990909090909091, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 656
goal_identified
=== ep: 657, time 33.818196058273315, eps 0.0010000000000048661, right preds for atk and def: 94/94 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 635
=== ep: 658, time 33.89842104911804, eps 0.001000000000004629, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 636
goal_identified
=== ep: 659, time 34.271876096725464, eps 0.0010000000000044032, right preds for atk and def: 108/108 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 638
goal_identified
goal_identified
goal_identified
=== ep: 660, time 36.35595512390137, eps 0.0010000000000041883, right preds for atk and def: 79/79 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 640
=== ep: 661, time 33.96541881561279, eps 0.001000000000003984, right preds for atk and def: 113/113 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 641
=== ep: 662, time 33.71622061729431, eps 0.0010000000000037897, right preds for atk and def: 85/85 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 642
goal_identified
=== ep: 663, time 30.833223819732666, eps 0.001000000000003605, right preds for atk and def: 85/85 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 643
goal_identified
=== ep: 664, time 36.787405014038086, eps 0.0010000000000034291, right preds for atk and def: 91/91 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 644
goal_identified
goal_identified
=== ep: 665, time 37.864707946777344, eps 0.001000000000003262, right preds for atk and def: 90/90 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 645
=== ep: 666, time 35.063199043273926, eps 0.0010000000000031028, right preds for atk and def: 80/80 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 646
=== ep: 667, time 35.33417582511902, eps 0.0010000000000029514, right preds for atk and def: 81/81 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 647
goal_identified
goal_identified
=== ep: 668, time 34.91063714027405, eps 0.0010000000000028075, right preds for atk and def: 105/105 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 648
=== ep: 669, time 38.60846257209778, eps 0.0010000000000026706, right preds for atk and def: 55/55 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 649
=== ep: 670, time 34.88254189491272, eps 0.0010000000000025403, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 650
goal_identified
goal_identified
=== ep: 671, time 34.81679129600525, eps 0.0010000000000024165, right preds for atk and def: 102/102 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 651
goal_identified
goal_identified
=== ep: 672, time 31.65113353729248, eps 0.0010000000000022985, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 652
goal_identified
=== ep: 673, time 33.85807228088379, eps 0.0010000000000021864, right preds for atk and def: 80/80 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 653
=== ep: 674, time 34.45615768432617, eps 0.00100000000000208, right preds for atk and def: 99/99 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 654
goal_identified
=== ep: 675, time 36.38797569274902, eps 0.0010000000000019785, right preds for atk and def: 100/100 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 655
goal_identified
=== ep: 676, time 34.4473397731781, eps 0.001000000000001882, right preds for atk and def: 79/80 = 0.9875, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 676
=== ep: 677, time 34.02988123893738, eps 0.0010000000000017903, right preds for atk and def: 73/73 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 657
=== ep: 678, time 36.329517126083374, eps 0.0010000000000017029, right preds for atk and def: 84/84 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 658
goal_identified
goal_identified
goal_identified
=== ep: 679, time 33.744341135025024, eps 0.0010000000000016198, right preds for atk and def: 81/81 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 659
goal_identified
=== ep: 680, time 31.104356288909912, eps 0.0010000000000015409, right preds for atk and def: 75/75 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 660
=== ep: 681, time 33.25136208534241, eps 0.0010000000000014656, right preds for atk and def: 76/76 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 661
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 682, time 33.40170621871948, eps 0.0010000000000013943, right preds for atk and def: 69/69 = 1.0, score_diff 4, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 662
goal_identified
goal_identified
=== ep: 683, time 33.51675796508789, eps 0.0010000000000013262, right preds for atk and def: 95/95 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 663
goal_identified
goal_identified
=== ep: 684, time 30.784685850143433, eps 0.0010000000000012616, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 664
=== ep: 685, time 33.421196937561035, eps 0.0010000000000012, right preds for atk and def: 86/86 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 665
goal_identified
=== ep: 686, time 35.11464023590088, eps 0.0010000000000011415, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 666
=== ep: 687, time 36.16772675514221, eps 0.0010000000000010857, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 667
=== ep: 688, time 37.22644352912903, eps 0.0010000000000010328, right preds for atk and def: 78/78 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 668
goal_identified
goal_identified
=== ep: 689, time 31.329988956451416, eps 0.0010000000000009825, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 669
goal_identified
=== ep: 690, time 33.83369207382202, eps 0.0010000000000009346, right preds for atk and def: 85/85 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 670
goal_identified
=== ep: 691, time 34.34160017967224, eps 0.001000000000000889, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 671
=== ep: 692, time 34.944441080093384, eps 0.0010000000000008457, right preds for atk and def: 108/108 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 672
goal_identified
=== ep: 693, time 31.821770191192627, eps 0.0010000000000008045, right preds for atk and def: 83/83 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 673
=== ep: 694, time 33.65609169006348, eps 0.0010000000000007653, right preds for atk and def: 106/107 = 0.9906542056074766, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 694
=== ep: 695, time 33.57575559616089, eps 0.0010000000000007277, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 674
=== ep: 696, time 39.85378623008728, eps 0.0010000000000006924, right preds for atk and def: 63/63 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 675
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 697, time 38.10123038291931, eps 0.0010000000000006586, right preds for atk and def: 99/99 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 677
goal_identified
=== ep: 698, time 37.52412438392639, eps 0.0010000000000006265, right preds for atk and def: 90/90 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 678
=== ep: 699, time 35.84767389297485, eps 0.001000000000000596, right preds for atk and def: 106/107 = 0.9906542056074766, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 699
goal_identified
goal_identified
goal_identified
goal_identified
=== ep: 700, time 34.44190955162048, eps 0.0010000000000005668, right preds for atk and def: 92/92 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 679
=== ep: 701, time 33.888787508010864, eps 0.0010000000000005393, right preds for atk and def: 81/81 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 680
=== ep: 702, time 34.31913995742798, eps 0.0010000000000005128, right preds for atk and def: 80/80 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 681
goal_identified
=== ep: 703, time 34.0407555103302, eps 0.001000000000000488, right preds for atk and def: 77/77 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 682
=== ep: 704, time 33.297696352005005, eps 0.001000000000000464, right preds for atk and def: 103/103 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 683
goal_identified
=== ep: 705, time 32.53534770011902, eps 0.0010000000000004415, right preds for atk and def: 65/65 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 684
goal_identified
=== ep: 706, time 35.46409368515015, eps 0.00100000000000042, right preds for atk and def: 64/64 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 685
=== ep: 707, time 33.59284830093384, eps 0.0010000000000003994, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 686
goal_identified
goal_identified
goal_identified
=== ep: 708, time 35.217233657836914, eps 0.00100000000000038, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 687
goal_identified
=== ep: 709, time 36.52338409423828, eps 0.0010000000000003615, right preds for atk and def: 82/82 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 688
goal_identified
=== ep: 710, time 32.7681565284729, eps 0.0010000000000003437, right preds for atk and def: 105/105 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 689
goal_identified
=== ep: 711, time 33.938854694366455, eps 0.001000000000000327, right preds for atk and def: 81/81 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 690
goal_identified
=== ep: 712, time 33.733044385910034, eps 0.0010000000000003112, right preds for atk and def: 99/99 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 691
=== ep: 713, time 33.60566449165344, eps 0.001000000000000296, right preds for atk and def: 107/107 = 1.0, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 692
=== ep: 714, time 30.89005708694458, eps 0.0010000000000002815, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 693
=== ep: 715, time 35.71406531333923, eps 0.0010000000000002678, right preds for atk and def: 74/74 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 695
goal_identified
=== ep: 716, time 34.335625648498535, eps 0.0010000000000002548, right preds for atk and def: 101/101 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 696
goal_identified
goal_identified
=== ep: 717, time 33.37508583068848, eps 0.0010000000000002422, right preds for atk and def: 84/84 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 697
goal_identified
=== ep: 718, time 34.252453327178955, eps 0.0010000000000002305, right preds for atk and def: 117/118 = 0.9915254237288136, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 718
goal_identified
goal_identified
=== ep: 719, time 33.690531730651855, eps 0.0010000000000002192, right preds for atk and def: 81/81 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 698
goal_identified
=== ep: 720, time 36.05502772331238, eps 0.0010000000000002086, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 700
=== ep: 721, time 36.93159008026123, eps 0.0010000000000001984, right preds for atk and def: 94/95 = 0.9894736842105263, score_diff -3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 721
goal_identified
goal_identified
=== ep: 722, time 35.035982608795166, eps 0.0010000000000001887, right preds for atk and def: 75/75 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 701
goal_identified
=== ep: 723, time 38.454851388931274, eps 0.0010000000000001796, right preds for atk and def: 37/37 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 702
=== ep: 724, time 33.65210247039795, eps 0.0010000000000001707, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 703
goal_identified
=== ep: 725, time 36.61290621757507, eps 0.0010000000000001624, right preds for atk and def: 75/75 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 704
goal_identified
=== ep: 726, time 33.54847073554993, eps 0.0010000000000001544, right preds for atk and def: 79/79 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 705
goal_identified
=== ep: 727, time 30.940269947052002, eps 0.001000000000000147, right preds for atk and def: 97/97 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 706
goal_identified
goal_identified
=== ep: 728, time 33.31842827796936, eps 0.0010000000000001399, right preds for atk and def: 99/99 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 707
goal_identified
=== ep: 729, time 34.313719749450684, eps 0.001000000000000133, right preds for atk and def: 91/91 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 708
goal_identified
=== ep: 730, time 37.156190395355225, eps 0.0010000000000001264, right preds for atk and def: 93/93 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 709
=== ep: 731, time 36.28772711753845, eps 0.0010000000000001204, right preds for atk and def: 78/78 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 710
goal_identified
=== ep: 732, time 30.897339582443237, eps 0.0010000000000001145, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 711
goal_identified
=== ep: 733, time 33.79943561553955, eps 0.0010000000000001089, right preds for atk and def: 95/95 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 712
goal_identified
goal_identified
=== ep: 734, time 36.48104786872864, eps 0.0010000000000001037, right preds for atk and def: 77/77 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 713
goal_identified
=== ep: 735, time 34.874186515808105, eps 0.0010000000000000985, right preds for atk and def: 102/102 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 714
=== ep: 736, time 30.71758270263672, eps 0.0010000000000000937, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 715
=== ep: 737, time 34.35411477088928, eps 0.0010000000000000891, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 716
=== ep: 738, time 33.68126368522644, eps 0.0010000000000000848, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 717
goal_identified
=== ep: 739, time 34.36606955528259, eps 0.0010000000000000807, right preds for atk and def: 79/79 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 719
goal_identified
goal_identified
goal_identified
=== ep: 740, time 30.857679843902588, eps 0.0010000000000000768, right preds for atk and def: 66/66 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 720
=== ep: 741, time 37.9895977973938, eps 0.001000000000000073, right preds for atk and def: 101/101 = 1.0, score_diff -2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 722
goal_identified
=== ep: 742, time 37.31501913070679, eps 0.0010000000000000694, right preds for atk and def: 110/110 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 723
goal_identified
=== ep: 743, time 36.07695817947388, eps 0.001000000000000066, right preds for atk and def: 95/95 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 724
goal_identified
goal_identified
=== ep: 744, time 38.60229754447937, eps 0.001000000000000063, right preds for atk and def: 72/72 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 725
goal_identified
=== ep: 745, time 32.20289897918701, eps 0.0010000000000000599, right preds for atk and def: 72/72 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 726
goal_identified
goal_identified
goal_identified
=== ep: 746, time 34.42245388031006, eps 0.0010000000000000568, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 727
=== ep: 747, time 35.40805006027222, eps 0.001000000000000054, right preds for atk and def: 72/72 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 728
=== ep: 748, time 34.73693656921387, eps 0.0010000000000000514, right preds for atk and def: 80/80 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 729
=== ep: 749, time 31.30661630630493, eps 0.001000000000000049, right preds for atk and def: 82/83 = 0.9879518072289156, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 749
goal_identified
=== ep: 750, time 34.8130567073822, eps 0.0010000000000000466, right preds for atk and def: 91/91 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 730
goal_identified
goal_identified
=== ep: 751, time 34.044740200042725, eps 0.0010000000000000443, right preds for atk and def: 104/104 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 731
goal_identified
=== ep: 752, time 36.372546911239624, eps 0.001000000000000042, right preds for atk and def: 81/81 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 732
goal_identified
goal_identified
goal_identified
=== ep: 753, time 35.4994683265686, eps 0.0010000000000000401, right preds for atk and def: 112/112 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 733
goal_identified
=== ep: 754, time 37.736039876937866, eps 0.0010000000000000382, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 734
=== ep: 755, time 33.30386924743652, eps 0.0010000000000000362, right preds for atk and def: 72/72 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 735
goal_identified
goal_identified
=== ep: 756, time 33.95319485664368, eps 0.0010000000000000345, right preds for atk and def: 89/89 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 736
goal_identified
=== ep: 757, time 30.946841716766357, eps 0.0010000000000000328, right preds for atk and def: 72/72 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 737
goal_identified
=== ep: 758, time 33.75147843360901, eps 0.0010000000000000312, right preds for atk and def: 75/75 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 738
=== ep: 759, time 33.89041709899902, eps 0.0010000000000000297, right preds for atk and def: 79/79 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 739
=== ep: 760, time 34.037092447280884, eps 0.0010000000000000282, right preds for atk and def: 96/96 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 740
goal_identified
goal_identified
goal_identified
=== ep: 761, time 30.488781690597534, eps 0.001000000000000027, right preds for atk and def: 94/94 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 741
goal_identified
=== ep: 762, time 33.838626861572266, eps 0.0010000000000000256, right preds for atk and def: 92/92 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 742
goal_identified
=== ep: 763, time 38.464497804641724, eps 0.0010000000000000243, right preds for atk and def: 77/77 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 743
goal_identified
=== ep: 764, time 36.01473927497864, eps 0.0010000000000000232, right preds for atk and def: 85/85 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 744
=== ep: 765, time 36.32166790962219, eps 0.001000000000000022, right preds for atk and def: 69/69 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 745
goal_identified
=== ep: 766, time 30.652445793151855, eps 0.0010000000000000208, right preds for atk and def: 67/67 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 746
goal_identified
=== ep: 767, time 33.35316753387451, eps 0.00100000000000002, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 747
=== ep: 768, time 32.626710653305054, eps 0.0010000000000000189, right preds for atk and def: 65/65 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 748
goal_identified
goal_identified
=== ep: 769, time 33.619783878326416, eps 0.001000000000000018, right preds for atk and def: 73/73 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 750
=== ep: 770, time 30.788809299468994, eps 0.0010000000000000172, right preds for atk and def: 75/75 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 751
goal_identified
=== ep: 771, time 33.28297710418701, eps 0.0010000000000000163, right preds for atk and def: 80/80 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 752
goal_identified
=== ep: 772, time 33.58867788314819, eps 0.0010000000000000154, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 753
=== ep: 773, time 35.80985116958618, eps 0.0010000000000000148, right preds for atk and def: 117/117 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 754
goal_identified
=== ep: 774, time 33.31256985664368, eps 0.0010000000000000141, right preds for atk and def: 101/101 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 755
=== ep: 775, time 34.93289613723755, eps 0.0010000000000000132, right preds for atk and def: 71/71 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 756
goal_identified
goal_identified
=== ep: 776, time 35.55998659133911, eps 0.0010000000000000126, right preds for atk and def: 83/83 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 757
goal_identified
goal_identified
goal_identified
=== ep: 777, time 33.49395775794983, eps 0.0010000000000000122, right preds for atk and def: 88/89 = 0.9887640449438202, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 777
goal_identified
=== ep: 778, time 33.11698508262634, eps 0.0010000000000000115, right preds for atk and def: 90/90 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 758
=== ep: 779, time 31.328871726989746, eps 0.0010000000000000109, right preds for atk and def: 74/74 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 759
goal_identified
=== ep: 780, time 33.739781856536865, eps 0.0010000000000000104, right preds for atk and def: 96/96 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 760
=== ep: 781, time 33.772653579711914, eps 0.00100000000000001, right preds for atk and def: 101/101 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 761
=== ep: 782, time 36.10077714920044, eps 0.0010000000000000093, right preds for atk and def: 59/59 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 762
=== ep: 783, time 30.551755905151367, eps 0.001000000000000009, right preds for atk and def: 83/83 = 1.0, score_diff -1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 763
=== ep: 784, time 33.39520573616028, eps 0.0010000000000000085, right preds for atk and def: 68/69 = 0.9855072463768116, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 784
goal_identified
goal_identified
goal_identified
=== ep: 785, time 33.5591254234314, eps 0.001000000000000008, right preds for atk and def: 95/95 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 764
goal_identified
=== ep: 786, time 37.116331577301025, eps 0.0010000000000000076, right preds for atk and def: 89/89 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 765
goal_identified
=== ep: 787, time 34.14194059371948, eps 0.0010000000000000074, right preds for atk and def: 71/71 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 766
goal_identified
goal_identified
=== ep: 788, time 35.16736888885498, eps 0.001000000000000007, right preds for atk and def: 102/102 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 767
goal_identified
goal_identified
=== ep: 789, time 34.13276505470276, eps 0.0010000000000000067, right preds for atk and def: 73/73 = 1.0, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 768
goal_identified
=== ep: 790, time 33.965155601501465, eps 0.0010000000000000063, right preds for atk and def: 69/69 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 769
goal_identified
goal_identified
goal_identified
=== ep: 791, time 34.217430114746094, eps 0.001000000000000006, right preds for atk and def: 91/91 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 770
goal_identified
=== ep: 792, time 34.809186697006226, eps 0.0010000000000000057, right preds for atk and def: 103/104 = 0.9903846153846154, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 792
=== ep: 793, time 34.784992933273315, eps 0.0010000000000000054, right preds for atk and def: 98/98 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 771
goal_identified
=== ep: 794, time 35.10737156867981, eps 0.0010000000000000052, right preds for atk and def: 93/93 = 1.0, score_diff 1, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 772
goal_identified
=== ep: 795, time 32.44758486747742, eps 0.001000000000000005, right preds for atk and def: 76/76 = 1.0, score_diff 0, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 773
goal_identified
goal_identified
goal_identified
=== ep: 796, time 35.076844930648804, eps 0.0010000000000000048, right preds for atk and def: 91/91 = 1.0, score_diff 3, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 774
goal_identified
goal_identified
=== ep: 797, time 31.672871828079224, eps 0.0010000000000000044, right preds for atk and def: 83/84 = 0.9880952380952381, score_diff 2, tot learning steps 10 (total env steps 3001)
== current size of memory is eps 21 > 20 and we are deleting ep 797
goal_identified
